{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 10:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there', 'where', 'has', 'eh', 'seen', 'not', 'social', 'is', \"i'll\", 'my', 'tavern', 'pick', 'normal', 'forget', 'hold', 'with', 'hello', 'me', 'last', 'back', 'drink', 'on', 'you', 'of', 'the', \"i'm\", 'name', 'barney_gumble', 'meet', 'anybody', 'effervescent', 'yeah', 'ice', 'check', 'an', 'to', 'one', 'whats', 'matter', 'another', 'your', 'self', 'enhance', 'problems', 'moe_szyslak', 'bart_simpson', 'puke', 'give', 'homer_simpson', 'listen', 'hey', 'rotch', 'lately', \"moe's\", 'these', 'and', 'elite', 'carve', \"you're\", 'only', 'i', 'skills', 'catch', 'gonna', 'got', 'days', 'mike', 'homer', 'little', 'moe', 'should'}\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    word_set = set()\n",
    "    for word in text:\n",
    "        word_set.add(word)\n",
    "    print(word_set)\n",
    "    vocab_to_int = {word: i for i, word in enumerate(word_set)}\n",
    "    int_to_vocab = {i: word for word, i in vocab_to_int.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    punc_dict = {}\n",
    "    \n",
    "    punc_dict['.'] = \"||Period||\"\n",
    "    punc_dict[','] = \"||Comma||\"\n",
    "    punc_dict['\"'] = \"||Quotation_Mark||\"\n",
    "    punc_dict[';'] = \"||Semicolon||\"\n",
    "    punc_dict['!'] = \"||Exclamation_Mark||\"\n",
    "    punc_dict['?'] = \"||Question_Mark||\"\n",
    "    punc_dict['('] = \"||Left_Parentheses||\"\n",
    "    punc_dict[')'] = \"||Right_Parentheses||\"\n",
    "    punc_dict['--'] = \"||Dash||\"\n",
    "    punc_dict['\\n'] = \"||Return||\"\n",
    "    \n",
    "    return punc_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rusty', 'chance', 'cell', 'bursts', 'monster', 'duty', 'tow-joes', 'eggs', 'themselves', 'xanders', 'wise', 'afraid', \"'im\", 'beefs', 'ball', 'skinner', 'trench', 'perverse', \"industry's\", 'well', 'escort', 'pull', 'whining', 'sometime', 'stepped', 'able', 'hears', 'cup', 'just', 'shortcomings', 'snake_jailbird:', 'attractive_woman_#1:', 'later', 'coffee', 'kent', 'wiggle', 'jimmy', 'putty', 'online', 'housewife', 'shall', 'choking', \"b-52's:\", 'refill', 'passed', 'uneasy', 'teacup', 'conclusions', 'cutie', 'publish', 'interested', 'shades', 'upn', \"aren'tcha\", 'honey', 'street', 'whoever', 'realized', 'served', 'spitting', 'a-a-b-b-a', 'small', 'frankenstein', 'quarry', \"buffalo's\", 'heavens', 'coney', \"clancy's\", 'got', 'excellent', 'donuts', 'nemo', 'say', 'shutup', 'uglier', 'tree_hoper:', 'priority', 'glorious', 'nominated', 'quimby_#2:', 'mortal', 'sat', 'straighten', 'western', '91', 'lump', 'ad', 'scatter', \"i-i'm\", 'notch', 'gulps', 'tentative', 'chauffeur:', \"wouldn't-a\", 'behind', 'spy', \"squeezin'\", 'spit-backs', 'sending', 'bold', 'indifferent', 'polygon', 'buds', 'sampler', 'gotta', 'minus', 'remote', 'played', \"game's\", 'direction', 'careful', 'bowling', 'unforgettable', 'tank', '/mr', 'e', \"puttin'\", '1979', 'harm', 'beer-dorf', 'ram', 'santeria', 'exit', 'espousing', 'positive', 'believe', 'moe-near-now', 'dropped', 'chips', 'presses', 'appeals', 'savvy', 'waterfront', 'lady_duff:', 'hosting', 'memories', 'center', 'grunts', 'lessons', 'beating', 'proper', 'schabadoo', 'priceless', 'generously', 'disappeared', 'fast-paced', 'folk', 'semi-imported', 'machine', 'hobo', 'listened', 'padres', 'anti-lock', 'chicken', 'pal', 'civilization', 'determined', 'smell', 'falsetto', 'palm', 'ears', 'value', 'clammy', 'pages', 'overhearing', 'works', 'picked', 'fledgling', 'elmer', 'nope', 'conversion', 'arise', 'singers:', 'urinal', 'pudgy', 'parked', 'drift', 'closer', \"bettin'\", 'hero-phobia', 'yawns', 'wasting', 'dad', 'minimum', 'chick', 'uh', 'scary', 'uniforms', 'quarter', 'languages', 'grains', 'hat', 'brassiest', 'crowd:', 'ape-like', 'should', 'mirthless', 'verdict', \"wino's\", 'wrestling', 'warranty', 'roof', 'changed', 'occurs', 'nash', 'caveman', 'drunkenly', 'awkwardly', 'clothespins', 'yours', 'cecil_terwilliger:', 'perfunctory', 'champignons', 'errrrrrr', 'closed', 'fayed', 'six', 'maya:', 'barney_gumble:', 'swan', 'sooner', 'marge', 'call', \"kiddin'\", 'dumptruck', 'little_man:', 'clandestine', 'hour', 'musta', 'slobs', 'demand', 'mason', 'stewart', 'diamond', 'delightfully', 'four', 'anti-crime', 'hottest', 'bleacher', 'jolly', 'clear', \"countin'\", 'sloe', 'persia', 'stories', 'heaven', 'middle', \"professor's\", 'options', 'klown', 'bannister', 'democrats', 'tv', 'aboard', 'tape', 'was', 'foundation', 'assumed', 'prompting', 'reciting', 'faulkner', 'outrageous', 'sloppy', 'selling', 'mitts', 'soup', 'opening', 'play', \"y'know\", \"how're\", 'grin', 'crowds', 'landfill', 'ron', 'died', 'talk', 'figure', 'moving', 'winnings', 'awful', 'title', 'payments', 'kentucky', 'displeased', 'thought_bubble_lenny:', 'bucket', 'deliberately', 'inspection', 'legally', 'burp', 'beligerent', 'meeting', 'montrer', \"'pu\", 'jeter', 'tummies', 'intriguing', 'victorious', 'frogs', 'drawing', 'down', 'across', 'doy', 'sweat', 'strolled', 'eddie:', 'tab', 'family-owned', 'zeal', 'cecil', 'toasting', 'wreck', 'goes', 'occasion', \"neat's-foot\", 'y-you', 'move', 'pictured', 'sadistic_barfly:', 'it:', 'prayer', 'omit', 'absentmindedly', 'way:', 'buzz', 'moe', \"family's\", 'rat', 'angry', 'stalin', 'slurps', 'crying', 'hug', 'hooters', 'phrase', 'taste', 'imagine', 'land', 'tester', 'whaddaya', 'cyrano', 'anymore', \"tap-pullin'\", 'help', 'endorsement', 'color', \"takin'\", 'agnes_skinner:', 'weekly', 'stomach', 'hygienically', 'grim', 'ladies', 'lay', 'slyly', 'alfred', 'sandwich', 'yammering', 'noosey', 'aquafresh', 'mumble', 'speaking', 'ducked', 'eve', 'george', 'nasty', 'piano', 'thoughts', 'courteous', 'heck', 'zinged', 'suds', 'south', 'flat', \"fallin'\", 'apron', 'dangerous', \"i'd'a\", 'abolish', \"patrick's\", 'during', 'williams', \"it'll\", 'peaked', 'keep', 'gonna', 'glen', 'combination', 'diving', 'donut', 'dinks', \"he'd\", 'candles', 'justice', 'kirk_voice_milhouse:', 'ratted', 'weirder', 'ziffcorp', 'carl:', 'west', 'neighboreeno', 'catty', 'mafia', 'treats', 'simultaneous', 'try', 'subject', 'clipped', 'valley', 'quick-like', 'hitchhike', 'ya', 'pfft', 'consciousness', 'solely', 'thanks', 'vengeful', 'thanksgiving', 'chained', 'knows', 'loan', 'hands', 'sneeze', \"homer's\", 'stretch', 'jacksons', 'frog', '||right_parentheses||', 'country-fried', 'aggravazes', \"you'll\", \"coaster's\", 'betrayed', 'anger', 'rationalizing', 'reasons', 'today/', 'alien', 'el', 'penmanship', 'spare', 'extra', 'p-k', 'não', 'toms', 'cheapskates', 'misconstrue', 'gang', 'hooray', 'tar-paper', 'friendly', \"fun's\", 'sodas', 'disillusioned', 'ling', 'insensitive', 'carny:', 'friday', 'bleeding', 'meant', 'wazoo', 'talked', 'jerks', 'locklear', 'agent_miller:', 'who', 'landlord', 'duffed', 'mindless', 'politics', 'rights', 'discuss', 'babar', 'insulin', \"nothin'\", 'taken', 'alcoholism', 'hollywood', 'late', 'foibles', 'dance', 'failed', 'increasingly', 'register', 'peanuts', 'shard', 'refund', 'american', 'almost', 'won', 'curious', 'dallas', 'basement', 'sugar-me-do', 'cartoons', 'ingredient', 'index', 'disco', 'dollface', 'explaining', 'shrieks', 'jack', 'lost', 'please/', 'dying', 'soul-crushing', 'books', 'beats', 'bedtime', 'billion', 'kisser', 'grace', 'recent', 'stadium', 'refreshingness', 'story', 'arrest', 'reluctant', 'ebullient', 'moe_recording:', 'struggling', 'alec_baldwin:', 'breaks', 'punch', 'rome', 'lame', 'light', 'freshened', 'oblongata', 'rain', 'wrong', \"enjoyin'\", 'restless', 'puff', 'double', 'spoon', \"poisonin'\", 'beaumarchais', 'churchill', 'influence', 'sue', 'endorsed', 'ashtray', 'unavailable', 'metal', 'sperm', 'musses', 'charity', 'eighty-three', 'upbeat', 'announcer:', 'verticality', 'u', 'ride', 'wednesday', \"she'll\", 'fritz:', \"raggin'\", 'flatly', 'appear', 'stooges', \"rentin'\", 'admirer', 'charges', 'dateline', 'flush', 'hanging', 'worried', 'wang', 'john', 'placing', 'mariah', 'van', 'would', 'junior', 'gloop', 'mmm', 'cupid', 'stolen', 'chief', 'celebrities', 'unrelated', 'tha', 'flailing', 'uh-oh', 'stupidest', 'ready', 'lied', 'frazier', 'intervention', 'ambrose', 'been', 'grenky', 'frightened', 'assent', 'anybody', 'hans:', 'collapse', 'billiard', 'flips', 'spreads', 'certain', 'lobster-politans', 'olive', 'bill', 'contemptuous', 'underpants', 'novel', 'shock', 'solid', 'stuff', 'ago', 'closet', 'lisa_simpson:', 'fabulous', 'len-ny', 'ends', 'screams', 'ga', 'acquitted', 'irrelevant', 'laughs', \"high-falutin'\", \"should've\", 'product', 'illustrates', \"seein'\", 'calmly', 'poulet', 'rage', 'federal', 'minors', 'nucular', 'too', 'joined', 'videotaped', \"cuckold's\", 'song', 'mint', 'meaningfully', \"cat's\", 'again', 'bindle', 'project', 'naively', 'arguing', 'focused', 'ruint', 'tells', 'remodel', 'utility', \"askin'\", 'rag', 'cola', 'jig', 'cuckoo', 'beat', 'standing', 'bedridden', 'nurse', 'hootie', 'same', 'murdered', 'cheers', 'fork', 'swamp', 'thousands', 'bow', 'packets', 'alive', 'death', 'pardon', 'signal', 'lousy', 'moe-clone:', \"stinkin'\", 'cliff', 'colorado', 'i-i', 'eye-gouger', 'pulling', 'hmmm', 'remembering', 'lucinda', 'cop', 'alibi', 'scrape', 'legs', 'ear', 'pizzicato', 'chinua', 'dum-dum', 'campaign', 'asses', 'ruby-studded', 'satisfaction', 'broadway', 'badge', 'buying', \"calf's\", 'defiantly', 'gary:', 'elect', 'grunt', \"won't\", 'available', 'aerosmith', 'lotsa', 'absentminded', 'trivia', 'sigh', 'shoes', 'shut', 'grabbing', 'poem', 'cranberry', 'shores', 'package', 'de-scramble', 'forty-seven', 'eggshell', 'faint', 'whole', 'salad', 'huhza', 'exhibit', 'radiation', 'decide:', 'playing', 'contract', 'genius', 'carney', 'born', \"betsy'll\", 'nasa', 'scout', 'depressed', 'amber_dempsey:', 'cruiser', 'something', 'ancient', 'musketeers', 'byrne', 'self-centered', 'sob', 'thnord', 'painted', 'worthless', 'ridiculous', 'sees/', 'rainbows', 'donation', 'wheeeee', 'encores', 'buyer', 'tofu', 'woooooo', 'catching', 'dreamy', 'reluctantly', 'gus', 'bye', 'fevered', 'red', 'high-definition', 'be-stainèd', 'cousin', 'created', \"how's\", 'jernt', 'its', 'agh', 'catch', 'clips', 'concentrate', 'inspire', 'confidentially', 'detail', \"bar's\", 'rockers', 'right', 'aunt', 'sold', 'urge', 'brightening', 'shaky', 'coherent', \"starla's\", 'town', 'answered', 'anyone', 'alone', 'mccarthy', 'make', 'declare', 'anguished', \"comin'\", 'deals', 'muscle', 'brine', 'phony', 'mostly', 'pain', 'rotch', 'stand', 'gunk', 'hemoglobin', 'ehhhhhhhh', 'helped', 'that', 'astrid', 'loud', 'sell', 'barflies:', 'lighter', 'premise', 'temporarily', 'tavern', 'sideshow_bob:', 'reads', 'irs', 'add', 'roses', 'shack', 'nigeria', 'night-crawlers', 'astronaut', 'pride', 'blossoming', 'fondest', 'hit', 'puke-holes', 'payday', 'roy', 'obvious', 'well-wisher', 'bears', 'grandé', 'if', 'dizzy', 'matter-of-fact', 'naturally', 'breathless', 'hillbillies', 'accent', 'routine', 'housing', 'toledo', 'behavior', 'chuckling', 'heavyset', 'delete', 'open-casket', 'lard', 'glasses', 'flag', 'break', 'game', 'hates', 'arrange', \"kids'\", 'remorseful', 'compliment', 'shotgun', 'blackjack', \"treatin'\", 'contemplated', 'inanely', 'agent_johnson:', 'sensible', '$42', 'bride', 'eight', 'brings', 'kansas', 'jobs', 'ford', 'startled', 'dateline:', 'whatcha', \"s'pose\", \"workin'\", 'answers', \"tryin'\", 'crowbar', 'wooden', 'streetlights', 'effervescent', 'couple', 'forgiven', 'installed', 'maiden', 'manjula', 'period', 'morlocks', 'saved', 'brain', 'gig', 'angrily', 'sobo', 'steel', 'pretty', 'haws', 'publishers', 'lovelorn', 'closes', 'hugh', 'rainier', 'cheerier', \"tomorrow's\", 'continuing', 'ribbon', \"s'okay\", 'maman', 'super-nice', 'blubberino', 'ding-a-ding-ding-ding-ding-ding-ding', 'cerebral', 'obese', 'outstanding', 'stocking', 'enterprising', 'tv_daughter:', 'smurfs', 'including', 'wishes', \"ol'\", 'mcstagger', 'man:', 'sit', 'animals', 'customers-slash-only', 'swe-ee-ee-ee-eet', 'faiths', 'eye', 'bottle', 'store', 'umm', 'laid', 'whip', 'hilarious', 'baseball', 'gut', 'noose', 'damage', 'halfway', \"springfield's\", 'tempting', 'drug', 'vacation', 'ease', 'issuing', 'hanh', 'amanda', 'seriously', 'seem', 'legend', \"couldn't\", 'slight', 'talkative', 'work', 'indigenous', 'snake', 'talkers', 'plain', 'pirate', 'till', 'team', 'what-for', 'scores', 'planned', 'wittgenstein', 'moonlight', 'sun', 'gosh', 'conditioning', 'horribilis', 'moron', 'unbelievably', 'pillows', 'label', 'caused', 'terrible', 'tight', 'considering', 'talk-sings', 'grade', 'kirk_van_houten:', 'stickers', 'trust', 'fill', 'cats', 'eyesore', 'relative', 'suspect', 'model', 'wizard', 'suffering', 'photographer', 'apulina', 'mistresses', 'bachelorette', 'seductive', 'darjeeling', 'idea', 'button-pusher', 'third', 'happier', 'ninth', 'mistakes', 'hits', 'ragtime', 'throat', 'mic', 'barber', 'perverted', 'martini', 'drop', 'likes', 'bathtub', 'following', 'romance', \"when's\", 'devils:', 'milk', 'hunka', \"one's\", \"drexel's\", 'wha', 'dashes', 'safely', 'stagey', 'such', 'butter', 'hangover', 'fustigate', 'distributor', 'around', 'knock', 'permanent', 'heals', 'dearest', 'colonel:', '530', 'panicked', 'boisterous', 'winner', 'solo', 'explain', 'begin', 'walking', 'will', 'testing', 'comedy', 'louder', 'slice', 'edelbrock', 'souvenir', 'college', \"tree's\", 'coming', 'trainers', 'thorough', 'presided', 'extremely', 'drives', 'sec', 'choked', 'fell', 'afternoon', 'hellhole', 'swine', 'perfume', 'cheerleaders:', 'fustigation', 'hops', 'california', 'pay', 'sucker', 'krabappel', 'eaters', 'literary', 'people', 'guilt', 'fat_in_the_hat:', 'helicopter', '||comma||', 'accepting', \"wife's\", 'insults', \"moe's\", 'subscriptions', 'prettied', 'labels', 'depression', 'sharps', 'bobo', 'befouled', 'wad', 'pepper', 'atlanta', \"kid's\", 'ignorant', 'pen', 'hilton', 'higher', 'dirty', 'both', 'modest', 'mystery', 'stay-puft', 'aims', 'barn', 'hideous', 'sector', 'ooh', 'worked', 'o', 'covers', 'this', 'extended', 'finger', 'dirge-like', ':', 'absolut', 'gentles', 'dawning', 'womb', 'looks', 'ireland', 'teenage_bart:', 'woman', 'bubble', 'whisper', 'all:', 'jailbird', 'life-sized', 'cut', 'showing', 'hammer', 'sniffs', 'mt', 'connection', 'duff_announcer:', 'bets', 'marriage', 's-a-u-r-c-e', 'dame', \"ma's\", 'hydrant', 'kent_brockman:', 'tooth', 'make:', 'wakede', 'majority', 'screw', 'confident', \"o'clock\", 'with', 'moon', 'hello', 'conspiratorial', 'correcting', \"readin'\", 'jury', 'kramer', 'brockman', 'firing', 'bagged', 'marched', 'traitors', 'defected', 'crack', 'i-i-i', 'therapy', 'minutes', 'regulars', 'miss', 'shyly', 'sanitary', 'frink-y', 'sounded', 'complaining', \"waitin'\", 'tiger', 'off', 'easier', 'support', 'though:', \"shootin'\", 'electronic', 'incredible', 'wooooo', 'spending', 'full-time', 'anonymous', 'captain:', 'oughtta', 'canyonero', 'industry', 'dishonor', 'diet', 'truck_driver:', 'unfresh', 'lizard', \"liberty's\", 'pine', 'lifts', 'lance', 'tax', 'deli', 'nibble', 'sizes', 'toy', 'african', 'mumbling', \"nothin's\", 'application', 'woozy', 'bet', 'adeleine', \"how'd\", 'side:', 'whee', 'problem', 'conditioners', 'close', 'points', 'protesters', 'smart', 'shorter', \"can't-believe-how-bald-he-is\", 'einstein', 'dee-fense', 'lenford', 'lobster-based', '||exclamation_mark||', \"floatin'\", 'finished', 'mailbox', 'earlier', 'rainforest', 'lecture', 'patron_#1:', 'u2:', 'dating', 'address', 'enjoyed', 'fondly', 'w', 'alfalfa', \"father's\", 'sixty', 'general', 'video', 'encouraged', 'jokes', 'probably', 'reentering', 'fires', 'fast', 'thirty-nine', 'stalwart', 'flanders', 'espn', 'looser', 'gunter:', 'kidney', 'farewell', 'benjamin', 'pridesters:', 'sickened', 'choice', 'jovial', 'chauffeur', 'embarrassing', 'often', 'crazy', 'chief_wiggum:', 'tragedy', 'wore', 'eliminate', 'inside', 'brow', 'charm', 'and/or', 'offensive', \"tony's\", 'cleveland', 'quadruple-sec', 'daniel', 'art', 'beyond', 'fold', 'shoo', 'joe', 'exciting', 'two-drink', 'fault', 'profiling', 'thing:', 'village', 'rounds', \"lenny's\", 'stares', 'senator', 'sets', 'refreshment', 'handoff', \"men's\", 'dang', 'three', 'man_with_tree_hat:', 'chili', 'show', 'scrubbing', 'mild', 'margarita', 'peter', 'jane', 'age', 'incognito', 'weight', 'bumpy-like', 'dismissive', 'solves', 'quick', 'choice:', \"thinkin'\", 'flown', 'jerk', 'sexton', 'cozies', 'get', 'hillary', 'conditioner', 'scare', 'hyahh', 'graveyard', 'boozehound', 'swallowed', 'th-th-th-the', 'compete', 'beans', 'cheaped', \"'cept\", 'brotherhood', \"havin'\", 'noticing', 'society_matron:', 'squabbled', 'legal', 'what', 'jeff_gordon:', 'combine', 'chateau', 'annual', 'sweetest', 'bills', 'also', 'car', \"bart's\", 'enemies', 'ones', 'needy', 'park', 'somewhere', 'dreamily', 'east', 'charlie:', 'bouquet', 'impending', 'commanding', 'craft', 'yell', 'scratcher', 'overflowing', 'groveling', 'spent', 'elaborate', 'sing', 'fica', 'outlive', 'finding', 'juke', 'raising', 'x', \"neighbor's\", 'smuggled', 'tradition', 'wa', \"we've\", 'newest', 'rabbits', 'option', 'hiya', 'new_health_inspector:', 'top', 'gay', 'midge', 'meyerhof', 'trolls', 'ghouls', 'effect', 'blame', 'blues', 'bolting', 'self-esteem', 'breaking', 'territorial', 'world', 'hourly', 'ned', \"livin'\", 'gator:', 'troy', 'expect', 'coincidentally', 'collette:', 'confession', \"man'd\", 'hoo', 'edgy', 'totalitarians', 'snap', 'jelly', 'mabel', 'hunger', 'doppler', 'example', 'princess', 'twelve', 'buttocks', 'hushed', 'loboto-moth', 'nothing', 'feet', 'teams', '_zander:', 'glen:', 'guts', 'attractive_woman_#2:', 'either', 'jumps', 'beef', 'yak', 'ugly', 'delivery', 'mop', 'upsetting', 'onto', 'hitler', 'intention', 'allow', 'equivalent', 'pouring', 'gardens', 'mocking', 'sneak', 'tanked-up', 'updated', 'reviews', 'inflated', 'cheese', 'string', 'superior', \"fryer's\", 'heads', 'villanova', 'winces', 'awww', 'bus', 'two', 'broom', 'frontrunner', 'milhouse', 'good-looking', 'grateful', 'naegle', 'recommend', 'cookies', 'philosophic', '1989]', 'spooky', 'hated', 'trashed', 'schizophrenia', 'tale', 'housework', 'brilliant', 'jaegermeister', 'peabody', 'midnight', 'results', 'tail', 'lewis', 'gimmicks', 'time', 'sixty-nine', 'papa', 'pretzel', 'candy', 'department', 'button', 'maximum', 'citizens', 'loved', 'degradation', 'because', 'grind', 'done', \"england's\", 'skills', 'voted', 'rapidly', 'forty-five', 'sooo', 'like', 'distaste', 'humanity', 'methinks', 'knuckles', 'spite', 'owns', 'hooch', 'peppers', 'crank', 'missing', 'eats', 'perplexed', 'timbuk-tee', 'sometimes', 'um', 'forty-nine', 'suing', 'gambler', 'ever', 'hugh:', 'brainheaded', 'vanities', 'springfield', 'ointment', \"renee's\", 'warn', 'lists', 'introduce', \"time's\", 'clientele', 'anthony_kiedis:', 'horror', 'dilemma', 'tv_wife:', 'jesus', 'principal', 'stern', 'high', 'brave', 'funds', 'understood:', 'w-a-3-q-i-zed', 'eaten', 'waist', 'stupid', 'kazoo', 'moonshine', 'ignoring', \"ain't\", 'generosity', 'beached', 'pursue', 'dammit', 'watching', 'pants', 'cappuccino', 'm', 'stranger:', 'bridges', 'hearts', \"toot's\", 'thomas', 'overstressed', 'declan_desmond:', 'dry', 'bury', 'schmoe', 'shill', 'almond', 'widow', 'keeps', 'slapped', 'pointless', \"collector's\", '||return||', 'ice', 'joey_kramer:', '10:15', 'shutting', 'drunkening', 'unusual', 'shoulders', 'unjustly', 'baby', 'advertise', 'bees', 'beaumont', 'lennyy', 'y', 'began', 'hop', 'suddenly', 'driver', 'transmission', 'pasta', 'breakfast', 'knuckle-dragging', 'pub', 'gumbo', '100', 'moved', 'published', 'brother', \"school's\", 'rhode', 'needed', 'wrestle', 'meal', 'enforced', 'crimes', 'all-all-all', 'skoal', 'mayor_joe_quimby:', 'tropical', 'michael', 'nervously', 'women', 'depending', 'mortgage', 'youuu', 'emporium', 'crony', 'eu', 'knit', 'runs', 'however', 'earth', 'seek', 'forever', 'part-time', 'heartless', '||period||', 'david', 'intense', 'crisis', 'crippling', 'injury', 'nerve', 'exquisite', 'awfully', 'march', 'strictly', 'atari', 'wiping', \"other's\", 'taxi', 'worse', 'painless', 'sledge-hammer', 'jukebox', 'flash-fry', 'eyeballs', 'dark', 'winston', \"homer'll\", 'tied', 'glum', 'carefully', 'dogs', 'ruined', 'serious', 'infestation', 'this:', 'bee', 'young_moe:', 'sponsoring', 'twelveball', 'steamed', 'eighteen', 'theory', 'woman:', 'army', 'groans', 'lookalike:', 'cool', 'witches', 'without:', 'drawn', 'wire', 'wheel', \"world's\", 'plan', 'mid-seventies', 'lou:', 'experiments', \"'tis\", \"it's\", 'mary', 'so-called', 'wheels', 'stab', 'threw', 'shush', 'exclusive:', 'mediterranean', 'helen', 'dude', 'shopping', 'singing/pushing', 'yes', 'bono', 'easily', 'seymour_skinner:', 'har', 'divine', 'klingon', 'became', 'dentist', 'other', 'beers', 'temp', 'decency', 'iranian', 'lenny', 'choices:', 'has', 'mushy', 'sponsor', 'card', 'any', 'milhouses', 'frat', 'intoxicated', 'passion', 'pernt', 'and-and', 'low-blow', 'strategy', 'cents', 'brown', 'end', 'zero', 'asked', 'trapped', 'music', 'desire', 'tenuous', 'quit', 'fair', 'giving', 'quotes', 'finance', 'threatening', 'wok', 'radishes', 'toward', 'old-time', 'adopted', 'nein', 'counter', 'shaken', 'shove', 'honeys', 'rev', 'fools', 'tyson/secretariat', 'mater', 'mines', 'few', 'germs', 'amnesia', 'shoe', 'ninety-seven', 'tow-talitarian', 'curds', 'boozy', 'indeed', 'kim_basinger:', 'jay:', 'yard', 'wagering', 'teacher', 'grammar', 'oak', 'based', 'runaway', 'conclude', 'cueball', 'wake', 'stock', 'smugglers', 'committee', 'pigtown', 'surgeonnn', 'big', 'unattractive', 'know', 'clean', 'beam', 'invite', 'fired', \"who'da\", 'mexican', 'moe-ron', 'running', 'even', \"breakin'\", 'listen', 'gesture', 'slick', 'mall', 'un-sults', 'lawyer', 'disappointed', \"soakin's\", 'grumpy', 'moon-bounce', 'simpsons', 'proposing', 'actor', 'film', 'chocolate', 'cocking', 'gives', 'hubub', 'motor', 'banned', 'snort', 'wrap', \"snappin'\", 'dipping', 'steaming', 'cruel', \"singin'\", 'jigger', 'normals', 'commission', 'tire', 'burnside', 'biggest', 'priest', 'random', 'fatso', 'chase', 'loyal', 'mexican_duffman:', 'he', 'measure', 'raggie', 'happiness', 'al', 'wiggum', 'throw', 'cheated', 'rom', 'boring', 'inserted', 'spender', 'wood', 'folks', 'dessert', 'frink', 'bear', 'sense', 'indicates', 'wham', 'cash', 'tow', 'city', 'fist', 'blowfish', 'average-looking', 'highball', 'gary_chalmers:', 'except', 'said', 'blue', 'pointed', 'dae', 'racially-diverse', 'carlson', 'expert', 'barbed', 'louie:', 'weirded-out', 'owe', 'mis-statement', 'thoughtless', 'calls', 'amazed', 'delicate', 'marshmallow', 'blessing', 'midge:', 'hotline', 'snotty', 'warm_female_voice:', 'traffic', \"wait'll\", 'pepto-bismol', 'chest', 'upset', 'action', 'shoulda', 'greatest', \"we'll\", 'smoke', 'characteristic', '_eugene_blatz:', 'doug:', 'have', 'sour', 'seamstress', 'ineffective', 'drollery', 'blind', 'sink', 'buttons', 'howya', 'lover', 'crowded', \"what'll\", 'young_barfly:', 'koi', 'superpower', 'thru', 'grinch', 'eddie', 'stones', 'despite', 'drinking:', 'count', 'artist', 'colossal', 'whup', '3', \"somebody's\", 'manipulation', 'friendship', 'marge_simpson:', 'shaker', 'muscles', 'life-threatening', 'eco-fraud', 'awkward', 'bart', 'working', 'contact', 'health_inspector:', 'e-z', 'melodramatic', 'ziff', 'casual', 'means', 'lise:', 'plants', 'venom', 'ancestors', 'sickly', 'rich', \"heat's\", 'vance', 'disco_stu:', 'assert', 'showered', \"y'see\", 'ooo', 'lie', 'straight', \"that'll\", 'beep', 'butterball', 'chubby', 'canoodling', 'oh-so-sophisticated', 'kemi', 'stole', 'gabriel:', 'calvin', 'intelligent', 'market', 'boozer', 'sedaris', 'sponge', 'restaurant', '_powers:', 'mrs', 'tried', 'feels', 'lucius', 'through', 'jump', 'man', 'satisfied', 'dictating', 'harvesting', 'dies', 'possibly', 'backward', 'difference', 'bashir', 'scent', 'black', 'emphasis', 'settles', 'pusillanimous', 'lee', 'swimmers', 'billboard', 'covering', 'links', 'morose', 'boy', 'unsanitary', 'hooky', 'told', 'eh', 'youngsters', 'felony', 'broke', 'engine', 'depository', 'fastest', 'seconds', \"o'\", 'falcons', 'ceremony', 'miserable', 'meet', 'madison', 'reed', 'someone', 'matter', \"hole'\", 'edge', 'edna', 'point', 'dramatic', 'pulled', 'whaaa', 'obsessive-compulsive', 'jacks', 'launch', 'muffled', 'intruding', 'michael_stipe:', 'clearing', 'starlets', 'begging', 'their', 'doubt', 'everybody', 'reunion', 'madonna', 'situation', 'unlike', 'ballclub', 'goal', 'apartment', 'respect', 'conference', 'haw', 'chuckle', 'bail', 'tsking', 'girl', 'barney', 'code', 'camp', 'nuts', 'chub', 'accept', 'known', 'writing', 'ha-ha', 'carl_carlson:', 'spied', 'twenty-four', 'toe', 'stingy', 'maude', 'parenting', 'greatly', 'lushmore', 'pitch', 'religion', 'throws', 'turning', 'suru', 'angel', 'upon', 'spend', 'mommy', 'pas', 'focus', 'fleabag', 'rip', 'county', 'occupancy', 'ma', 'plywood', 'finishing', 'bono:', 'bar-boy', \"hasn't\", 'dig', 'schnapps', 'murdoch', 'jukebox_record:', \"challengin'\", 'champion', 'record', 'festival', 'rice', 'enter', 'krusty_the_clown:', 'hippies', 'coupon', 'nature', 'whether', 'murderously', 'bourbon', 'cost', 'haiti', 'moe-lennium', 'really', 'disappear', 'million', 'ate', 'bounced', 'cattle', 'language', 'tuborg', 'ah-ha', 'wine', 'remembers', 'sorry', 'ripcord', 'officer', 'chow', 'calm', 'serum', 'waste', '_marvin_monroe:', 'over-pronouncing', 'driving', 'twins', 'aid', 'figures', 'reynolds', 'amid', 'drederick', \"usin'\", 'ocean', 'thrust', 'relationship', 'tracks', 're-al', 'macgregor', 'twenty-six', 'access', 'week', \"where'd\", 'platinum', 'days', 'lowering', 'numbers', 'ivory', 'dumbass', 'perfect', \"yieldin'\", 'renee:', 'mad', 'gator', 'players', 'shaggy', 'labor', 'saget', 'madman', 'way', 'design', 'corner', 'fixes', 'winning', 'source', 'slogan', 'elocution', 'fantasy', 'habitrail', 'rem', 'brusque', 'sight-unseen', 'scornful', 'larry', \"ladies'\", 'buffalo', 'involving', 'invited', 'windowshade', 'jubilant', 'pets', 'normal', 'seems', 'nick', \"children's\", 'habit', 'suit', 'interrupting', 'lighten', 'purse', 'blinded', 'chug-monkeys', 'aiden', 'mini-dumpsters', 'moesy', 'products', 'creeps', 'awe', 'slugger', 'onions', 'attack', '1895', 'barkeep', 'universe', 'trying', 'eww', 'grocery', 'stay', 'initially', 'important', 'vomit', 'faceful', 'then', 'shout', 'tonic', \"bringin'\", 'graves', 'towed', 'dime', 'agents', 'vin', 'horns', 'dunno', 'domestic', 'whale', 'patrons:', 'bellyaching', 'fragile', 'hank_williams_jr', 'pews', 'presentable', \"idea's\", 'backing', 'rods', 'addiction', 'wieners', 'unhook', 'feast', 'specials', 'co-sign', 'slaves', 'janette', 'doreen', \"town's\", 'kiss', 'fifth', 'though', 'smug', 'flew', 'tying', 'snail', 'virtual', 'indifference', 'organ', 'danny', 'lord', 'zoomed', \"startin'\", 'kodos:', 'agency', 'nauseous', 'shakes', 'sentimonies', 'aah', 'shark', 'frosty', 'hand', 'turn', 'bartenders', 'cat', 'boxers', 'completely', 'going', 'transfer', 'invisible', 'harder', 'loathe', 'baritone', 'perch', 'naked', 'isle', 'getcha', 'seeing', \"payin'\", 'teenage_barney:', 'pulls', 'dennis_kucinich:', 'cheesecake', 'trunk', 'plow', 'refreshing', 'sketch', 'tear', 'devastated', 'chuck', 'mix', 'eurotrash', 'nevada', 'expose', 'booking', 'burt', 'therapist', 'acting', 'wussy', 'nice', 'pee', 'disposal', 'hangout', 'accelerating', 'friction', 'sauce', 'enjoys', 'darkest', 'mamma', 'shelbyville', 'hunting', 'stools', 'crinkly', 'radical', 'sequel', 'shop', 'oil', 'bike', 'handler', 'follow', 'smokes', 'image', 'ball-sized', 'shreda', 'delivery_boy:', 'kemi:', 'giant', 'neon', 'hair', 'proves', 'duel', 'heart', 'milks', \"soundin'\", 'natural', 'offa', 'suppose', 'burps', 'poisoning', 'blobbo', 'sexy', 'bust', 'nah', 'drummer', 'sniper', 'certified', 'crumble', 'sarcastic', 'crushed', 'helpless', 'jerry', 'fierce', 'shesh', 'la', 'yelling', 'sieben-gruben', 'married', 'powered', 'mac-who', 'premiering', 'furniture', 'quitcher', 'choked-up', 'buddha', 'audience', 'lady', 'bedbugs', 'newly-published', 'vacuum', 'ned_flanders:', 'plug', 'eyes', 'strong', 'sweaty', 'tastes', 'other_player:', \"ball's\", 'payback', 'moustache', \"barney's\", 'better', 'warning', 'lemme', 'human', 'they', 'strains', 'much', 'left', 'vigilante', 'annoyed', 'psst', 'bunion', 'divorced', 'exited', 'nonchalant', 'hers', 'irishman', 'guinea', 'cough', 'occurrence', 'effigy', 'form', 'business', 'chanting', 'academy', 'patty', 'cigarette', 'cause', 'slobbo', 'empty', 'nooo', 'confidential', 'changing', 'skeptical', 'handed', 'dumbbell', 'leno', 'real', 'loves', \"depressin'\", 'resist', 'accurate', 'losing', 'mustard', 'employees', 'bachelor', 'disguised', 'joy', 'face', 'breathalyzer', 'tolerance', 'doooown', 'exactly', 'men:', 'artie_ziff:', 'cowboys', 'scanning', 'favor', 'booze', 'yee-haw', 'hot-rod', 'notably', 'piece', 'badly', \"kearney's_dad:\", 'fountain', 'lucius:', 'hoping', 'aside', 'pip', 'hate', \"queen's\", 'leprechaun', 'on', 'killing', 'fights', 'othello', 'german', 'souped', 'fbi_agent:', 'gal', 'rats', 'badmouth', 'dumbest', 'specializes', 'error', 'orgasmville', 'or', 'killer', 'lear', 'release', 'suicide', 'pretending', 'bums', 'bright', 'boyhood', 'collateral', 'composer', 'ivy-covered', \"crawlin'\", 'automobiles', 'danish', 'kennedy', \"you've\", 'cares', 'repeated', 'cesss', 'awake', 'wave', 'arts', 'stinks', 'paint', 'geysir', 'ninety-eight', \"tinklin'\", 'aggravated', 'irish', 'candidate', 'meteor', 'break-up', 'speak', 'woodchucks', 'compressions', 'die', 'corpses', 'additional-seating-capacity', 'into', 'sweetie', 'proof', 'civic', 'bidet', 'superhero', 'shells', 'sassy', 'burns', 'johnny_carson:', 'voodoo', \"plaster's\", 'mini-beret', 'luckily', 'bras', 'prize', 'barkeeps', 'denser', 'strangles', 'nameless', 'grrrreetings', 'rekindle', 'voyager', 'quiet', 'deny', 'al_gore:', 'raise', 'pats', 'leftover', 'those', 'understood', 'figured', 'sheets', 'hollowed-out', 'fletcherism', 'belt', 'air', 'go', 'year', 'soothing', 'jay_leno:', 'mobile', 'fears', 'three-man', 'togetherness', 'enabling', 'limericks', 'wally', 'cummerbund', 'sweater', 'wings', 'gregor', 'queen', 'resigned', 'narrator:', 'hyper-credits', 'tv_husband:', 'parasol', 'malfeasance', 'perking', 'given', 'grandkids', 'reasonable', 'bumbling', 'muslim', 'blank', 'telemarketing', 'carmichael', 'office', 'taunting', 'shares', \"bashir's\", 'bible', 'hell', 'hustle', 'smells', 'diddilies', 'feelings', 'good', 'eighty-five', 'gag', 'doing', \"duelin'\", 'dog', 'compadre', 'wish', 'hard', 'victim', \"friend's\", 'hail', 'character', 'wudgy', 'calling', 'lloyd', 'astronauts', \"wallet's\", 'glove', 'safer', 'apu_nahasapeemapetilon:', 'hook', 'shrugging', 'innocence', 'pall', 'road', 'dean', 'triumphantly', 'fortensky', 'poetics', 'swear', 'grub', 'handing', 'dull', 'pinball', 'name', 'memory', 'worst', 'badmouths', 'gets', 'pleased', \"she's\", 'allegiance', \"'er\", 'slays', 'fireworks', 'anxious', 'sobs', 'er', 'staying', 'phase', 'back', 'contractors', 'tomato', 'hub', 'agree', 'andy', 'sleigh-horses', 'cotton', 'lindsay_naegle:', 'kinderhook', 'popped', 'she', '_montgomery_burns:', 'wounds', 'answering', 'factor', 'little', 'stood', 'prison', 'ripped', 'negative', 'comeback', 'apology', 'pile', 'reserve', 'boo', 'babe', 'wishful', 'extreme', 'cries', 'edna-lover-one-seventy-two', 'amber', 'mags', 'blob', 'libraries', 'anyhow', '35', 'your', 'simplest', 'griffith', 'salvador', 'president', 'boggs', 'rope', 'hampstead-on-cecil-cecil', 'ho-la', 'life', 'times', 'loser', 'crew', 'yuh-huh', 'encore', 'instrument', 'the_rich_texan:', 'violin', 'government', 'thousand', 'faced', 'dealt', 'telegraph', 'fox_mulder:', 'pure', 'clincher', 'snatch', 'leaving', 'unison', 'feeling', 'creature', 'new', 'masks', '©', 'nursemaid', 'insurance', \"ma'am\", 'low', 'decent', \"somethin's\", 'control', 'honor', 'delightful', 'fruit', 'catholic', 'rather', 'shakespeare', 'flaming', 'pink', 'typing', 'sucking', 'grumbling', 'cow', 'moans', 'cheap', 'hiding', 'evil', 'very', 'violations', 'recreate', 'moe-heads', 'dumb-asses', 'awareness', 'stage', 'throwing', \"'cause\", 'forbidden', 'princesses', 'prejudice', 'balloon', 'thirty-thousand', 'planet', 'older', 'used', 'jackpot-thief', 'declan', 'paid', \"now's\", 'peanut', 'canyoner-oooo', 'halvsies', 'saying', 'hopeful', 'bed', 'pour', 'tipsy', 'feminist', 'adult', 'eternity', \"mecca's\", 'fuhgetaboutit', 'cover', 'spread', 'spellbinding', 'her', 'massive', \"moe's_thoughts:\", 'distinct', 'person', 'consoling', 'koji', 'snide', 'ew', 'undies', 'deacon', 'fight', 'right-handed', 'bide', \"somethin':\", 'refresh', 'presents', 'hall', 'stu', '50-60', 'harmony', 'airport', 'windex', 'heroism', 'gasps', 'coaster', \"drinkin'\", 'emergency', 'gimmick', 'express', 'hm', 'must', 'store-bought', 'shaking', 'musical', 'hairs', 'voice:', 'homer_simpson:', 'thankful', 'cuz', 'hundreds', 'sudden', 'scam', 'thirty', 'roller', 'coins', 'lookalike', 'proudly', 'had', 'pope', 'she-pu', 'okay', 'sketching', 'yourse', 'touch', 'troy:', 'rock', 'pockets', 'soul', 'hoagie', 'drunk', 'examples', 'isotopes', 'disaster', 'haplessly', 'homie', 'young_marge:', 'drove', \"robbin'\", 'bully', 'steak', 'stripes', 'correction', 'sausage', 'lovely', 'taylor', 'stars', 'counting', 'leathery', 'in-in-in', 'casting', 'tell', 'listens', 'drapes', 'clap', 'dancing', 'result', 'scene', \"stayin'\", 'opportunity', 'flower', 'friend:', 'guess', 'fancy', 'complaint', 'ads', 'vengeance', 'acquaintance', 'poin-dexterous', 'harv:', \"ridin'\", 'whatchamacallit', 'puzzled', 'saint', 'washed', 'patting', 'might', 'steam', 'ihop', 'full-blooded', 'sass', 'son-of-a', 'helps', 'suspicious', 'fonda', 'house', 'multi-national', 'pizza', 'hibbert', 'hardy', 'yelp', 'derek', 'mostrar', 'happy', 'pre-recorded', 'aw', 'restroom', 'jägermeister', 'four-star', 'nos', 'chip', 'ehhhhhh', 'journey', 'gamble', 'kidneys', 'bartender', 'share', 'tomahto', 'helping', 'class', 'community', 'everyone', 'cocks', 'most:', 'wipe', \"tab's\", 'anything', 'freely', 'splash', 'fire', 'blaze', 'cricket', 'lift', 'change', 'tie', 'prohibit', 'supports', 'nahasapeemapetilon', 'carll', 'event', 'fool', 'drunks', 'wienerschnitzel', 'wars', 'lips', 'less', 'bum:', 'suspended', 'sticking-place', 'law-abiding', 'junkyard', 'blend', 'cases', 'reserved', 'pool', 'huggenkiss', \"can'tcha\", 'son', 'reckless', 'beauty', 'station', 'ungrateful', 'jail', 'thoughtful', 'weather', 'press', 'ugliness', 'reward', \"who's\", 'although', 'ohmygod', 'amount', 'stagehand:', 'customers', 'gin', 'nbc', 'grab', \"beer's\", 'catch-phrase', 'expensive', 'der', 'latour', 'acceptance', 'perfected', 'contented', 'stir', 'pennies', 'ab', 'silent', 'beneath', 'palmerston', 'starters', 'band', 'alarm', 'taxes', \"don't\", 'greystash', 'guff', 'motto', 'cute', 'balls', 'luck', 'medieval', 'felt', 'smiling', 'appealing', 'excuse', 'pre-columbian', 'pawed', 'nelson', 'boozebag', 'studio', 'fumes', 'sleeping', 'super', 'the', 'procedure', 'examines', 'gil_gunderson:', 'sorts', 'dollar', 'brawled', 'hmf', 'steely-eyed', 'flying', 'barney-type', 'bugging', 'awed', 'lainie:', 'julienne', 'tv_father:', 'incredulous', 'stationery', 'finest', 'dejected', 'luckiest', 'johnny', 'a', 'squadron', 'did', 'cologne', 'exchanged', 'sunny', 'stumble', 'email', 'illegal', 'ahem', 'loss', 'strap', 'kahlua', 'partially', \"jackpot's\", 'amazing', 'gentleman:', 'l', 'tolerable', 'kinds', 'boned', 'presto:', 'easy-going', 'let', 'officials', 'floating', 'lovejoy', 'terrified', 'stinky', 'prime', 'manfred', \"games'd\", 'dislike', 'juan', 'lachrymose', 'polenta', 'seas', 'exasperated', \"department's\", 'caught', 'punching', 'amends', 'so', 'cards', 'unlocked', \"what'sa\", 'nickels', 'runners', 'alky', 'handling', 'starla', 'david_byrne:', 'jams', 'andrew', 'brandy', 'cakes', 'picnic', 'tickets', 'yup', 'lazy', 'manjula_nahasapeemapetilon:', 'century', 'feed', 'huge', 'furiously', \"liftin'\", \"others'\", 'achebe', 'broken:', 'haikus', 'cronies', \"life's\", 'sympathizer', 'wedding', 'cherry', 'row', 'buzziness', 'linda', 'wholeheartedly', 'praise', 'clench', 'convenient', 'mate', 'grave', 'sent', 'apart', \"messin'\", 'grandmother', 'kneeling', 'fella', 'brick', 'detective_homer_simpson:', 'lenny_leonard:', 'yellow', 'lose', 'murmurs', 'owes', 'pumping', 'firm', 'afloat', 'handsome', 'recruiter', 'sight', 'aged_moe:', 'half-day', 'awesome', 'distraught', \"brockman's\", 'groin', 'letter', 'made', 'trick', 'digging', 'blamed', 'don', 'bronco', 'fiction', 'nelson_muntz:', 'sagely', 'rasputin', 'walks', 'approval', 'stool', 'female_inspector:', 'post-suicide', 'stayed', 'fellow', 'needs', 'wild', 'sitcom', 'fly', 'tubman', 'encouraging', 'oh-ho', 'lime', \"mopin'\", 'holding', 'spoken', 'looting', \"buyin'\", 'scrutinizes', 'tapping', 'came', 'combines', 'read:', 'gossipy', 'declared', 'spot', 'morning-after', 'ore', 'honored', 'c', 'taking', 'america', 'blissful', 'renee', 'obama', 'spirit', 'beer:', 'ripping', 'ye', 'steal', 'filled', 'at', 'ralph', 'gentlemen', 'laughter', 'stiffening', 'bit', 'loneliness', 'bupkus', \"renovatin'\", 'stored', 'settled', 'vacations', 'terror', 'kissing', 'arab_man:', 'ails', 'losers', 'perón', 'grants', 'nickel', 'correct', 'kegs', 'disdainful', 'passes', 'cozy', 'chosen', 'pushes', 'husband', 'flames', 'young_homer:', 'massachusetts', 'donate', 'hawking:', 'dan_gillick:', 'punches', 'chapstick', 'crowd', 'saturday', \"sittin'\", 'deadly', 'trusted', 'system', 'syndicate', \"that'd\", 'judgments', 'disgusted', 'ha', 'eager', 'quarterback', 'archaeologist', 'aer', 'clapping', 'allowance', 'quietly', 'missed', 'kills', 'layer', 'punk', 'spamming', 'hmm', 'guys', \"pressure's\", 'occupied', 'onassis', 'p', 'reaction', 'congratulations', 'sec_agent_#2:', 'bartholomé:', 'besides', 'passports', 'partner', \"ragin'\", \"lady's\", 'summer', \"i'unno\", 'you', 'wiener', 'samples', 'insured', 'whistles', 'kadlubowski', 'applesauce', 'six-barrel', \"swishifyin'\", 'sensitivity', 'trustworthy', 'shower', 'breakdown', 'fake', 'clothespins:', 'gumbel', 'rush', 'romantic', 'wowww', 'man_at_bar:', 'frescas', 'book_club_member:', 'ran', 'duffman:', 'lofty', 'capuchin', 'please', 'a-b-', 'frozen', 'mission', 'bird', 'entertainer', 'bag', 'abercrombie', 'nigerian', 'tv-station_announcer:', 'everywhere', 'temper', 'stinger', 'potatoes', 'appointment', 'eva', 'are', 'type', 'take', 'sly', 'thumb', 'authorized', 'linda_ronstadt:', 'neanderthal', 'wants', 'tidy', 'krusty', 'decided', 'finally', 'squeezed', 'wuss', 'hangs', 'ninety-nine', '||dash||', 'jackson', 'watched', 's', '||semicolon||', 'student', 'science', 'unearth', 'promotion', 'joking', 'kidding', 'fellas', 'richer', 'extinguishers', 'cleaned', 'supply', 'wolveriskey', 'chumbawamba', 'loafers', 'applicant', 'wraps', 'illegally', 'annus', 'toys', 'cockroach', 'whenever', 'cushions', 'actress', 'sacrilicious', 'there', 'blows', 'moan', 'head', 'reality', \"what's\", 'compare', 'weeks', 'clenched', 'confidence', 'ahead', 'glass', 'sangre', 'plant', 'bite', 'pro', 'concerned', 'destroyed', 'laney', 'nonsense', 'cheer', 'countryman', 'detective', 'alma', 'price', 'football', 'bliss', 'shuts', 'tick', 'drown', 'grand', 'seat', 'wish-meat', 'coach:', 'learned', 'waitress', 'inning', 'gulliver_dark:', 'quimbys:', 'tsk', 'youth', 'match', \"meanin'\", 'chuckles', 'sisters', 'dungeon', 'service', 'limber', 'pharmaceutical', 'uhhhh', 'chunk', 'snake-handler', 'dollars', 'busy', 'traitor', 'when', 'cadillac', 'paparazzo', 'remaining', 'ambrosia', 'barstools', 'tip', 'proud', 'distance', 'sing-song', 'safecracker', \"don'tcha\", 'admit', 'ken:', 'check', 'news', 'one', 'refinanced', 'wife', 'joint', 'funniest', 'ordered', 'guard', 'yoo', 'furry', 'porn', 'jack_larson:', 'mmm-hmm', 'hate-hugs', 'moe-clone', 'pit', 'ech', 'war', 'sister-in-law', 'jerk-ass', 'susie-q', 'computer', 'charge', 'k', 'mistake', 'me', 'ultimate', 'offended', 'international', 'naval', 'evasive', 'rings', 'fishing', 'relieved', 'viva', 'attempting', 'theatah', 'according', 'flexible', 'batmobile', 'massage', 'ping-pong', 'mccall', 'am', 'congoleum', 'recorder', 'alternative', 'eyeball', 'imaginary', 'chunky', 'vermont', 'smithers', 'marry', 'ideal', 'november', 'butts', 'car:', 'senators', 'perhaps', 'flayvin', 'albert', 'energy', 'cold', 'as', 'rector', 'sweetheart', 'cuddling', 'writers', 'soir', 'shape', 'treehouse', 'predecessor', 'selfish', 'keeping', 'score', 'hike', 'underwear', 'k-zug', 'babies', \"could've\", 'arse', 'effervescence', 'trash', 'lives', 'snackie', 'living', 'infiltrate', 'rob', 'kearney_zzyzwicz:', 'statues', 'church', 'give', 'microbrew', 'iran', 'kenny', 'richard:', 'wealthy', 'monorails', 'peeping', \"people's\", 'forgive', 'short', 'garbage', 'noise', \"poundin'\", 'read', 'faces', 'puffy', \"feelin's\", 'television', 'rolls', 'bubbles-in-my-nose-y', 'football_announcer:', 'growing', 'tourist', 'mansions', 'secret', 'maybe', 'criminal', 'trail', 'deal', 'pin', '3rd_voice:', 'hey', \"year's\", 'set', 'filth', 'laramie', 'crayola', 'only', \"hawkin'\", 'pronounce', 'ground', 'laws', 'leonard', 'reach', 'valuable', 'trucks', 'different', 'freedom', 'rebuttal', 'thousand-year', 'brief', 'fever', 'unless', 'hot', 'crow', 'insulted', \"c'mere\", 'businessman_#2:', 'job', 'ashamed', 'kid', 'pass', 'certainly', 'disgraceful', 'stairs', 'blur', 'defensive', 'ralph_wiggum:', 'place', 'otherwise', 'consulting', 'crestfallen', 'darn', 'pus-bucket', 'rubbed', 'single', 'happily:', 'interesting', 'picture', 'harvey', \"i'll\", 'venture', 'riding', 'dumpster', 'voters', 'yello', 'deliberate', 'discriminate', 'pulitzer', 'jackass', 'impatient', 'tree', 'dr', 'and', 'play/', 'forward', 'edison', 'anderson', 'robbers', 'dispenser', 'chipped', \"c'mon\", 'troubles', 'kicked', 'gasp', 'thirteen', 'drivers', 'speed', 'little_hibbert_girl:', 'poor', 'carnival', 'easy', 'shoots', 'intoxicants', 'mm-hmm', 'apu', 'sunk', 'putting', 'glitz', 'phone', 'natured', \"plank's\", 'propose', 'fighter', 'believer', 'brainiac', 'outlook', 'pajamas', 'ass', 'majesty', 'girlfriend', 'alls', 'bloodball', 'championship', 'lib', 'tactful', 'cheered', 'idioms', 'gestated', 'tremendous', 'bottles', 'advice', 'understanding', 'cutest', 'liser', 'faith', 'activity', 'return', 'thirty-five', 'trapping', 'gangrene', 'renders', \"stealin'\", 'mither', 'scooter', \"tester's\", 'lemonade', 'octa-', 'lungs', 'afterglow', 'germany', 'fighting', 'tired', 'lumpa', 'junebug', 'champ', 'recently', 'challenge', 'weak', 'crapmore', 'usual', 'freed', 'mother', 'pipe', 'incarcerated', \"writin'\", 'once', 'here', 'alcoholic', 'branding', 'fausto', 'excited', 'hounds', 'warned', 'forty-two', 'join', 'ironic', \"everyone's\", 'bucks', 'flack', \"edna's\", 'plaintive', \"i-i'll\", 'con', \"you'd\", 'technical', 'mount', \"doctor's\", 'snorts', 'nearly', 'cleaning', 'chinese', 'je', 'orifice', 'doof', \"g'on\", \"must've\", 'delicious', 'root', 'clone', 'do', 'special', 'assume', 'dennis_conroy:', 'retain', 'trip', \"they'll\", 'joining', 'hotel', 'sad', 'elephants', 'hostile', 'brothers', 'oils', 'wrote', 'not', '1973', 'ought', 'freeze', 'gone', 'our', 'kl5-4796', 'remembered', 'ees', 'barflies', 'rivalry', 'mr', 'delays', 'bitterly', 'scram', 'completing', \"mother's\", 'ronstadt', 'manboobs', 'miles', 'yo', 'each', 'frustrated', 'dead', 'burn', 'louisiana', 'strips', 'dive', 'silence', 'knowing', 'my', 'liquor', 'changes', 'erasers', 'jubilation', 'coin', 'monkeyshines', 'ticket', 'mimes', 'ventriloquism', 'rug', 'crime', \"'kay-zugg'\", 'appreciated', 'movement', 'mel', 'lead', 'brunswick', 'cauliflower', 'material', 'bull', 'nicer', 'geez', 'permitting', \"monroe's\", 'fun', 'comment', 'lurleen_lumpkin:', 'cleaner', 'ignorance', 'smile:', \"cheerin'\", 'holy', 'expecting', 'compared', 'slap', 'bill_james:', \"hobo's\", 'stirring', 'alpha-crow', 'cage', 'dory', 'edner', \"man's_voice:\", 'ominous', 'mill', 'backbone', 'rig', 'punkin', 'screws', 'tobacky', 'snotball', 'kill', 'held', \"'evening\", 'sealed', 'jamaican', 'flashbacks', 'lend', 'aggie', 'splattered', 'them', 'recall', 'developed', 'causes', 'lis', 'orders', \"'s\", 'huh', 'fudd', 'full', 'internet', 'since', 'ladder', 'lifters', 'painting', 'brace', 'all-star', 'lifestyle', \"what're\", 'sure', 'xx', 'nuked', 'sharity', \"phone's\", 'sweetly', 'professional', 'preparation', 'guide', \"he's\", 'dracula', 'scum', 'stupidly', 'knees', 'pointy', 'jam', 'attend', 'troll', 'host', 'si-lent', 'veteran', 'slender', 'planning', 'vicious', 'lurks', 'suits', 'gorgeous', 'coms', 'written', 'tony', 'wash', 'ah', 'americans', 'someday', 'fonzie', 'suspenders', \"'\", 'lucky', \"wearin'\", 'lap', 'fumigated', 'watch', 'pinchpenny', 'picky', 'macaulay', 'prep', 'bastard', 'militia', 'eat', 'guzzles', 'grieving', 'pathetic', 'file', 'than', 'italian', 'binoculars', 'police', '6', 'quero', 'theatrical', 'coma', 'operation', 'occurred', 'andalay', 'denver', 'homer_doubles:', 'enveloped', 'reached', 'schedule', 'morning', 'popular', 'spacey', 'scientific', 'shriners', 'dictator', 'squishee', 'legs:', 'takes', 'replace', 'accident', 'teen', 'spits', 'lately', 'capitol', 'man_with_crazy_beard:', 'zone', 'wolverines', 'against', 'ahhhh', 'hispanic_crowd:', 'b-day', 'dear', 'rife', 'fatty', 'improv', 'moment', 'de', 'socialize', 'bumped', 'noble', 'fit', 'burger', 'cooking', 'beeps', 'hardhat', 'cockroaches', 'snaps', 'oww', 'attention', 'rough', \"table's\", \"smackin'\", 'glee', 'fast-food', 'singer', 'rub-a-dub', 'temple', 'mexicans', 'pageant', \"i'm-so-stupid\", 'skydiving', 'dizer', 'lookalikes', 'virile', 'spinning', 'supermodel', 'yellow-belly', 'mechanical', 'fad', 'oof', 'found', 'paints', 'seen', 'where', 'forty', 'own', 'window', 'engraved', 'increased', 'dials', 'passenger', 'youse', 'squeal', 'locked', 'blocked', 'mouths', 'children', 'ali', 'sagacity', 'number', 'railroads', 'managed', 'terrace', 'pigs', 'wing', 'ways', \"donatin'\", 'lager', 'noggin', \"'n'\", 'regretted', 'politicians', 'schorr', 'salt', 'sanitation', 'over', 'polishing', 'spouses', 'pissed', 'public', 'hospital', 'monroe', 'named', 'happened', 'rip-off', 'squirrels', 'crooks', 'snout', 'here-here-here', 'desperately', 'rid', 'hole', 'pepsi', 'sports', 'cops', 'selma', 'outta', 'giggle', 'side', 'attracted', 'endorse', 'stamps', 'tons', 'starting', 'advance', 'counterfeit', 'reopen', 'copy', 'poster', 'broncos', 'saw', 'walk', 'corporation', 'boat', 'sucks', 'lying', 'stats', 'partly', 'shipment', 'solved', 'expired', 'environment', 'tinkle', 'highest', 'cocoa', 'guiltily', 'flash', 'meditative', 'turned', 'flustered', 'slaps', 'enlightened', 'drive', 'question', 'managing', 'gargoyle', 'disappointing', 'appearance-altering', 'museum', 'order', 'upgrade', \"aristotle's\", 'softer', 'neighborhood', 'crowned', 'maggie', 'is:', 'agent', 'backwards', 'look', 'goods', 'microphone', 'body', \"sat's\", 'go-near-', 'tomatoes', 'sideshow', \"summer's\", 'unbelievable', 'effects', 'twerpy', 'wildfever', 'clock', 'simpson', 'family', 'unsafe', 'nerd', 'capitalists', 'grienke', 'singing', 'yew', 'choices', 'lanes', 'kitchen', 'says', 'rainier_wolfcastle:', 'finish', 'gore', 'french', \"doin'\", 'safety', 'golden', 'bridge', 'chic', 'book', '[year', 'understand', 'feminine', 'coward', 'chair', 'heh', 'assassination', 'open', 'bob', 'shindig', 'plucked', 'actors', 'giggles', 'celebrate', 'all-american', 'generally', 'hurting', 'lisa', 'guy', 'manage', 'tatum', 'victory', 'mm', \"what'd\", 'fresh', 'lloyd:', 'daughter', 'marvin', 'icelandic', 'guessing', 'tapestry', 'stonewall', 'pickle', 'love-matic', '14', 'audience:', 'gayer', 'position', 'heliotrope', 'cannot', 'guest', 'jeff', 'pushing', 'appropriate', 'phasing', 'wade_boggs:', 'gas', 'simple', 'worldly', 'belly-aching', 'nap', 'computer_voice_2:', 'rest', 'exits', 'heartily', 'elizabeth', 'unsourced', 'aging', 'never', 'barter', 'ron_howard:', 'asleep', 'foot', 'veux', 'etc', 'clinton', \"i'd\", 'merchants', 'sucked', 'sang', 'uses', 'cake', 'daddy', 'mock', 'ingrates', 'cans', 'mulder', 'freaky', 'fox', 'poking', 'bedroom', 'carpet', 'bumblebee_man:', 'successful', 'julep', 'mike_mills:', 'burning', 'sales', 'th', 'species', 'impeach', 'far', 'statesmanlike', 'yesterday', 'today', 'chill', 'seething', 'attach', 'shirt', 'cooker', 'gun', '70', 'knocked', 'cursed', 'ohh', 'fat_tony:', 'bless', 'compliments', 'reading', 'population', 'test-', 'sounds', 'damn', 'toilet', 'words', 'micronesian', 'white', 'find', 'poker', 'coined', 'barf', 'repeating', 'envy-tations', 'now', 'creme', 'heard', 'seats', 'flush-town', 'pad', 'pyramid', 'sacrifice', 'tang', 'bank', 'squeeze', 'smitty:', 'sabermetrics', 'consider', 'droning', 'rotten', \"someone's\", 'recap:', 'executive', 'blow', 'blimp', 'choke', 'manager', 'yet', 'walther', 'shocked', 'researching', 'bring', 'acronyms', 'forehead', 'looked', 'reading:', \"they've\", 'hemorrhage-amundo', 'list', \"speakin'\", 'become', 'issues', 'lindsay', 'offshoot', \"isn't\", 'kick', 'bones', 'brain-switching', 'friend', 'unusually', 'men', 'advantage', 'wide', 'tuna', 'finale', 'rupert_murdoch:', 'mind-numbing', 'health', 'up', 'nectar', 'mirror', 'abandon', 'unkempt', 'swelling', \"somethin'\", 'southern', 'accusing', 'milhouse_van_houten:', 'background', 'beady', 'skunk', 'snapping', 'worldview', 'company', 'courts', 'aristotle:', \"spiffin'\", 'experience', 'social', 'gruesome', 'culkin', 'renew', 'sobriety', \"costume's\", 'france', 'shred', 'butt', 'cavern', 'patient', 'first', 'pause', 'undated', 'flourish', 'dough', 'showed', 'pilsner-pusher', 'apply', 'sea', 'egg', 'gin-slingers', 'old', 'repressed', 'mudflap', 'circus', \"shouldn't\", 'bake', 'state', 'bonding', 'pointing', 'fwooof', 'chapel', '_julius_hibbert:', 'getaway', 'more', 'du', 'realize', 'scratching', 'crossed', '50%', 'laughing', 'dana_scully:', 'presumir', 'reminded', 'mouth', 'elder', 'pays', 'scared', 'b', \"homer's_brain:\", \"rustlin'\", 'rent', 'scruffy_blogger:', 'cobbling', 'risqué', 'corkscrew', 'nigel_bakerbutcher:', 'crummy', 'act', 'chorus:', 'dexterous', 'goodbye', 'clears', 'wonder', 'face-macer', 'meaningless', 'dramatically', 'banquet', '7-year-old_brockman:', 'demo', 'run', 'adjourned', 'flanders:', 'thighs', \"d'ya\", 'unfortunately', 'chew', 'clothes', 'wall', 'fish', 'reporter', 'stained-glass', 'kickoff', 'aziz', 'trouble', 'protecting', 'shot', 'charlie', 'exact', '&', 'is', 'libido', 'whoa-ho', 'utensils', 'rascals', 'may', 'all', 'money', 'brockelstein', 'innocuous', 'crappy', 'problemo', \"tellin'\", '7g', 'country', 'coughs', 'various', 'assistant', 'justify', 'happens', 'farthest', 'male_inspector:', 'gift:', 'spotting', 'hurt', 'competitive', 'horrors', 'hungry', 'goldarnit', 'owner', 'fresco', 'skins', \"tv'll\", 'orphan', 'kang:', 'rumor', 'statistician', 'magazine', 'jeers', 'medical', 'vincent', 'retired', 'peter_buck:', 'billy_the_kid:', 'ruuuule', 'puke-pail', \"lookin'\", 'tablecloth', 'per', 'eyeing', 'annoying', 'every', 'bauer', 'pickled', 'quebec', 'sympathetic', 'yea', 'shareholder', 'whiny', 'blinds', 'race', 'botanical', 'portuguese', 'lottery', '-ry', 'making', 'dumb', 'mayan', 'maya', 'tv_announcer:', 'bullet-proof', 'force', 'another', 'clams', 'attraction', 'someplace', 'hotenhoffer', 'shtick', 'knowingly', 'avec', 'write', 'twentieth', 'sneering', 'fix', 'invulnerable', 'movies', 'took', '_hooper:', 'checking', 'slip', 'kindly', 'raccoons', \"gentleman's\", 'neighbors', 'bump', 'fury', '||left_parentheses||', 'compromise:', 'process', 'virility', 'kwik-e-mart', 'five-fifteen', 'benjamin:', 'stores', 'wait', 'superdad', 'duke', 'homeland', 'para', 'f-l-a-n-r-d-s', 'poorer', 'outside', 'sack', 'malted', 'easter', 'donated', 'anarchy', 'polish', 'hateful', 'lenses', 'j', 'lurleen', 'hose', 'rummy', 'washouts', 'purveyor', 'seven', 'joey', 'turns', 'hi', 'for', 'tabooger', 'tune', 'sheet', 'magic', 'broken', 'manatee', 'sleep', 'modestly', 'alcohol', 'partners', 'years', 'chin', \"guy's\", 'fence', 'tender', 'neat', 'bulldozing', 'these', 'sobbing', 'poured', 'teenage_homer:', 'can', 'quality', 'best', 'still', 'coy', 'sam:', \"goin'\", \"marge's\", 'moe_szyslak:', 'medicine', 'lobster', 'comedies', 'salary', 'spiritual', 'depressant', 'stan', 'szyslak', 'care', 'specific', \"let's\", 'united', 'adequate', 'curse', 'loaded', 'hooked', \"battin'\", 'love', 'sadder', 'eventually', 'investor', 'murmur', 'reporter:', 'socratic', 'toxins', 'diaper', 'pretzels', 'twelve-step', 'lessee', 'wondered', 'judges', 'else', 'surgery', 'reconsidering', 'wrecking', \"beggin'\", 'ingested', 'impress', 'aww', 'girls', 'yeah', 'kay', 'cowboy', 'brother-in-law', 'sky', 'witty', 'school', 'forgot', 'heart-broken', 'sub-monkeys', \"haven't\", 'guns', 'woo', 'head-gunk', 'wound', 'nantucket', 'keys', 'protesting', 'intakes', 'expense', 'powerful', 'long', \"round's\", 'triple-sec', 'mickey', 'firmly', 'daaaaad', \"fans'll\", 'moolah-stealing', 'whim', 'many', 'self', 'stops', 'dank', 'stuck', 'spilled', 'refiero', \"bartender's\", 'fire_inspector:', 'africanized', 'coal', 'fulla', 'camera', \"handwriting's\", 'chinese_restaurateur:', 'lingus', 'somehow', 'use', \"'morning\", 'i/you', 'luxury', 'bash', \"eatin'\", 'manchego', 'fry', 'continuum', 'relax', 'malibu', 'macho', 'jewelry', 'classy', 'quite', \"hell's\", 'terrifying', \"tv's\", 'election', 'spit', 'stein-stengel-', 'panties', 'lady-free', 'fontaine', 'handle', 'severe', 'champs', 'conversation', 'half-beer', \"d'\", 'when-i-get-a-hold-of-you', 'lovers', 'total', 'shelf', 'brakes', 'relaxed', 'jebediah', 'mona_simpson:', 'boxcar', 'courthouse', 'punishment', 'sudoku', \"man's\", 'survive', 'smoothly', 'revenge', 'occupation', 'dice', 'plum', 'muertos', 'typed', 'whoa', 'pills', \"lefty's\", \"that's\", 'workers', 'games', 'bushes', 'tough', 'storms', 'duff', 'parking', 'curiosity', 'cocktail', 'rafters', 'mixed', 'stalking', 'kirk', \"they'd\", 'microwave', 'temples', 'equal', 'ivana', 'diablo', 'tornado', 'dames', 'progress', 'bonfire', 'dash', 'sighs', 'lease', 'states', 'dress', 'flashing', \"jimbo's_dad:\", 'releases', 'occasional', 'alter', 'michelin', 'artie', 'versus', 'tanking', 'thoughtfully', 'blood', 'gasoline', 'dealie', 'sturdy', 'connor', 'away', 'judge_snyder:', \"bo's\", 'forget-me-shot', 'official', 'aghast', 'fall', 'syrup', '_burns_heads:', \"elmo's\", 'improved', \"carl's\", 'glad', 'formico', \"getting'\", 'tom', 'regret', 'ralphie', 'attached', 'harrowing', 'thing', 'savagely', 'column', 'easygoing', 'ginger', 'phlegm', 'radioactive', 'goodnight', 'speech', 'bluff', 'yourself', 'famous', 'further', 'enjoy', 'moxie', 'boneheaded', 'director:', 'muhammad', 'roz', 'bags', 'gently', \"linin'\", 'teach', 'mock-up', 'soap', 't-shirt', 'offense', 'lugs', 'ayyy', 'king', 'yep', 'fuzzlepitch', 'idiot', 'beautiful', 'chug', 'pep', 'exultant', 'disappointment', 'presidential', 'remember', 'surprised/thrilled', 'cab_driver:', 'reason', 'under', 'celeste', 'ehhhhhhhhh', 'barney-guarding', 'delts', 'gallon', 'polite', 'impressed', 'unexplained', 'sober', 'nation', 'local', 'slim', 'ditched', 'cheaper', 'sap', 'owned', 'plums', 'recipe', 'brooklyn', 'train', 'feat', 'pleasure', 'composite', 'studied', \"changin'\", 'beast', 'english', 'prints', 'sees', 'shoot', 'religious', 'to', 'schemes', 'knife', 'bookie', 'bigger', \"money's\", 'mention', \"there's\", 'looooooooooooooooooong', 'regretful', 'wonderful', \"bart'd\", 'prayers', 'caper', 'come', 'entire', 'nightmare', 'henry', 'buffet', 'we-we-we', 'pledge', 'bart_simpson:', 'anyway', 'incriminating', 'excavating', 'learn', 'flynt', 'kick-ass', 'geyser', 'bar:', 'pop', 'forgotten', 'newsies', 'program', 'kucinich', 'tasty', 'fat', 'cable', 'single-mindedness', 'waylon', 'cushion', 'common', 'omigod', 'nail', 'woulda', 'gluten', 'yards', 'bottoms', 'mckinley', 'mathis', 'swimming', 'court', 'ideas', 'reaching', 'grey', 'mellow', 'dna', 'hear', 'represents', 'generous', 'fiiiiile', 'donor', 'wasted', 'texan', 'pleasant', 'kissed', 'infatuation', \"dyin'\", 'maxed', 'sec_agent_#1:', 'being', 'ringing', 'planted', 'personal', 'sincere', 'sternly', 'kyoto', \"watchin'\", 'bugs', 'fainted', 'starving', 'scrutinizing', 'wins', 'sexual', 'estranged', 'minister', 'maitre', \"shan't\", 'disturbance', 'tomorrow', 'complete', 'suck', \"secret's\", 'names', 'fifty', 'together', 'enthusiasm', 'noooooooooo', 'beard', 'dressing', 'theater', 'arm-pittish', 'wobbly', 'half', 'dinner', 'birth', 'wiggle-frowns', 'forget-me-drinks', 'pian-ee', 'instead', 'roach', 'cajun', 'attractive', 'rash', 'leave', 'hiring', 'hammy', 'experienced', 'birthplace', 'jay', 'lily-pond', 'view', 'senators:', 'thawing', 'optimistic', 'wangs', 'churchy', 'neighbor', 'pointedly', 'eminence', 'trenchant', 'hidden', 'menlo', \"duff's\", 'customer', 'rhyme', 'snow', 'diminish', 'bar', 'judge', 'extract', \"larry's\", 'disgracefully', 'alva', 'sat-is-fac-tion', 'barney-shaped_form:', 'wayne:', 'playoff', 'tapered', 'itchy', 'boston', 'anniversary', 'mugs', 'reaches', 'dejected_barfly:', 'self-made', 'answer', 'releasing', \"y'money's\", 'wipes', 'spews', 'hibachi', 'shame', 'abusive', 'rickles', 'holidays', 'neither', 'waking-up', 'crawl', 'sustain', 'looking', 'knocks', 'out', 'terminated', 'young', 'transylvania', 'designated', 'sunday', 'sumatran', 'whoops', 'gutenberg', 'room', 'splendid', 'wanna', 'mine', \"dog's\", 'bottomless', 'abcs', \"america's\", 'fills', 'oddest', 'lincoln', 'sister', 'rafter', 'near', 'eighty-six', 'nudge', 'glitterati', 'sued', 'lock', 'breath', 'lonely', 'takeaway', \"brady's\", 'affection', 'prices', 'depressing', '_timothy_lovejoy:', 'harv', 'plans', 'moments', 'put', 'principles', 'title:', 'five', 'deep', 'square', 'swishkabobs', 'paying', 'adjust', 'diapers', 'lipo', 'glamour', 'avenue', 'start', 'raining', \"cleanin'\", 'ninety-six', 'badges', 'braun:', \"narratin'\", 'pair', 'voice_on_transmitter:', 'built', 'date', 'breathtaking', 'chapter', 'beards', 'how', 'synthesize', 'smallest', 'sugar', 'volunteer', 'gheet', 'jar', 'gotten', 'ahhh', 'bunch', 'between', 'hunter', \"this'll\", 'buddy', 'wildest', 'months', 'alley', 'carey', 'unfamiliar', 'peppy', 'decadent', 'forecast', 'complicated', 'the_edge:', \"here's\", 'rolled', 'helllp', 'everything', 'nascar', 'augustus', 'hang', 'disturbing', 'indecipherable', 'soot', \"g'night\", 'cross-country', 'inclination', 'belly', \"smokin'_joe_frazier:\", 'bartending', 'winded', 'groan', 'ehhh', 'fictional', 'thirty-three', 'wolfe', 'seminar', 'beloved', 'dressed', 'fireball', 'exhale', 'rub', 'vulgar', 'vestigial', 'greetings', 'portfolium', 'waylon_smithers:', 'watered-down', 'rude', 'slot', 'idiots', 'sign', \"something's\", 'nordiques', 'arimasen', 'two-thirds-empty', 'stillwater:', 'mahatma', 'yap', 'bid', 'mug', 'tiny', 'chug-a-lug', 'ze-ro', 'meals', 'feedbag', 'lots', 'elves:', 'piling', 'authenticity', 'panicky', 'ivanna', 'anywhere', 'truck', 'mind', 'statue', \"dolph's_dad:\", 'fingers', 'courage', 'present', 'four-drink', 'righ', 'funny', 'plastered', 'spanish', 'practically', 'knock-up', 'practice', 'arrived', 'crunch', 'underbridge', 'ons', 'mozzarella', 'who-o-oa', 'roz:', 'jerking', 'ecru', 'accidents', 'dealer', 'by', 'party', 'sniffles', 'slab', 'heavyweight', 'buddies', 'professor', 'doreen:', 'affectations', 'eighty-seven', 'rules', 'roll', 'nagurski', 'holds', \"gettin'\", 'photos', 'flea:', 'mouse', 'funeral', 'conversations', 'glyco-load', 'wayne', 'puke', 'bret:', 'homeless', 'admiration', 'ratio', 'miracle', 'teriyaki', 'author', 'dea-d-d-dead', 'patriotic', 'in', 'fourth', 'marguerite:', 'filed', 'carb', 'pocket', 'kept', 'evergreen', 'chicks', 'deeper', \"maggie's\", 'oooo', 'specialists', \"murphy's\", 'gruff', 'drink', 'think', 'a-lug', 'hawaii', 'supplying', 'novelty', 'nailed', 'cab', 'tasimeter', 'strategizing', 'foil', 'absolutely', 'gees', 'before', 'chum', 'dennis', 'insecure', 'fbi', 'kool', '||quotation_mark||', 'sotto', 'op', 'odor', '_babcock:', 'percent', 'boyfriend', 'ing', \"dad's\", 'ummmmmmmmm', 'hope', 'sick', 'belts', 'africa', 'referee', 'beverage', 'exploiter', 'rolling', 'need', 'offer', 'admiring', 'parents', '2nd_voice_on_transmitter:', 'usually', 'goblins', 'rule', 'therefore', 'forbids', 'lotta', 'text', 'greedy', 'thank', 'urban', 'dropping', 'britannia', 'sixty-five', \"chewin'\", 'bitter', 'deer', 'kissingher', 'surprising', 'pained', 'second', 'month', 'unfair', 'fantastic', 'quickly', 'christopher', 'yogurt', 'longer', 'eighty-one', \"we're\", 'bon', 'laugh', 'wishing', 'runt', 'fuss', 'charming', 'busted', 'feel', 'network', 'kidnaps', 'coyly', 'comic_book_guy:', 'hats', 'advertising', 'heading', 'na', 'cheering', 'imported-sounding', 'eightball', 'space-time', '2', 'we', 'befriend', 'clown-like', 'unattended', \"dimwit's\", 'warmly', 'horrible', 'forget', 'scornfully', 'lowest', 'case', 'while', 'mid-conversation', 'smile', 'located', 'windelle', 'snitch', 'fixed', 'ollie', 'frankly', 'horrified', 'whispered', \"stabbin'\", 'grampa', 'larson', 'imitating', 'shifty', \"today's\", 'jeez', 'things', 'rumaki', 'cannoli', 'bowled', 'darts', 'wondering', 'neil_gaiman:', 'cigars', 'crab', \"pullin'\", 'grubby', 'theme', \"she'd\", 'informant', 'glowers', 'begins', 'law', 'booze-bags', 'creepy', \"disrobin'\", 'steampunk', 'inserts', 'filthy', 'hockey-fight', 'clown', 'rewound', 'liven', 'playful', 'door', \"'ere\", \"makin'\", 'director', 'bars', \"fishin'\", 'raises', 'skinheads', 'wh', 'prettiest', 'led', 'getting', 'pickles', 'corkscrews', 'vote', 'scotch', 'grow', 'license', 'taps', 'delicately', 'pregnancy', 'lou', 'male_singers:', 'bowie', 'robin', 'career', \"i've\", '_kissingher:', 'save', 'history', 'disguise', 'boxer:', 'wolfcastle', 'bites', 'saving', 'scum-sucking', 'flaking', 'pretends', 'liable', 'pig', 'pleading', 'wearing', 'wrapped', 'pick', 'fail', \"boy's\", 'twenty-nine', 'cream', 'astonishment', 'connor-politan', 'enough', \"'em\", 'guttural', 'buy', \"mcstagger's\", 'businessman_#1:', 'nor', 'urine', 'japanese', 'ahh', 'excitement', 'delighted', 'miss_lois_pennycandy:', 'boxcars', 'bon-bons', 'homesick', \"hadn't\", 'stretches', 'pontiff', 'stop', 'leak', 'floor', \"lovers'\", 'box', 'promise', 'restaurants', 'formico:', 'gibson', 'eating', 'crayon', 'penny', 'dreary', \"s'cuse\", 'thought_bubble_homer:', 'sinkhole', 'windshield', 'driveability', 'name:', 'fine', \"listenin'\", 'peeved', 'blurbs', 'grabs', \"bladder's\", 'sweeter', 'paintings', 'plenty', 'polls', 'presidents', 'shooting', 'james', 'handshake', 'grudgingly', 'allowed', 'fdic', 'burt_reynolds:', 'nose', \"mtv's\", 'whatchacallit', 'touched', 'à', 'standards', \"smokin'\", 'politician', 'comforting', 'watered', 'innocent', \"who'll\", 'instantly', 'stevie', 'media', 'playhouse', 'brewed', 'motorcycle', 'uh-huh', 'considers', 'power', 'monday', 'calendars', 'said:', 'beer', 'society', 'disapproving', 'push', 'nonchalantly', 'thunder', 'serve', 'hare-brained', 'using', 'joke', 'winch', \"g'ahead\", 'wenceslas', 'literature', 'prolonged', 'nards', 'poke', 'evening', 'from', 'chipper', \"coffee'll\", 'borrow', \"spaghetti-o's\", 'trees', 'larry:', 'crap', 'swooning', 'cheery', 'argue', \"cont'd:\", 'poet', 'gums', 'entirely', 'ugh', 'couch', 'blade', 'sissy', 'dump', 'having', 'tips', 'pussycat', 'truth', 'inexorable', 'toss', 'homer', 'whistling', 'wisconsin', 'especially', 'swings', 'voicemail', 'associate', 'vehicle', 'briefly', 'level', 'bald', 'safe', 'already', 'super-genius', 'bleak', 'non-losers', 'plane', 'sponge:', 'sex', 'stands', 'shows', 'sticker', 'booth', 'belches', 'captain', 'crotch', 'unintelligent', 'test-lady', 'and:', 'squashing', 'squirrel', 'undermine', 'average', 'foam', 'absorbent', 'thesaurus', 'damned', 'booger', 'entrance', 'horses', 'sixteen', 'convinced', 'an', 'cuff', 'radiator', 'h', 'jumping', 'telephone', 'no', 'teeth', 'doors', \"stallin'\", \"tramp's\", 'tense', 'chilly', 'grease', 'boxer', 'done:', 'mike', 'goo', 'bothered', 'wanted', 'rueful', 'floated', 'iddilies', 'poetry', 'considering:', 'flophouse', 'actually', \"drawin'\", 'wells', 'ne', 'nightmares', 'homers', 'deeply', 'sadly', 'involved', 'rims', 'appreciate', 'furious', 'half-back', \"pope's\", \"washin'\", 'menacing', 'watt', 'banquo', 'stagy', 'chairman', 'menace', 'domed', 'dozen', 'tabs', 'renovations', 'belong', 'child', 'william', 'signed', 'necklace', \"he'll\", 'gags', 'coat', 'admitting', 'meaningful', 'win', 'raging', 'saga', 'cheat', 'build', \"tonight's\", 'season', 'fund', 'realizing', 'jogging', 'clearly', 'drains', 'enthusiastically', 'weird', 'i', 'grandiose', 'childless', 'nuclear', 'credit', \"hangin'\", 'blood-thirsty', 'triangle', 'lone', 'turkey', 'happily', 'be', 'saucy', 'warily', 'reader', 'frankie', 'robot', 'sweet', 'patrons', 'group', 'bad-mouth', 'ura', 'luv', 'until', 'abe', 'brains', 'kako:', \"cupid's\", 'düff', 'parrot', 'prince', 'founded', \"burnin'\", 'worry', \"showin'\", \"drivin'\", 'securities', 'predictable', 'talking', 'letters', \"wouldn't\", 'free', 'tearfully', 'evils', 'radio', 'rebuilt', 'fanciest', 'swatch', 'club', 'torn', 'castle', 'jacques:', 'flame', 'friends', 'gol-dangit', 'slightly', 'korea', 'alphabet', 'maintenance', 'lenny:', 'fat-free', \"nick's\", 'bloodiest', 'photo', 'stengel', 'discussing', 'rugged', 'ruled', 'billingsley', 'rat-like', 'table', 'sickens', 'forgets', 'went', 'norway', 'dregs', 'rap', 'wears', 'dryer', 'popping', 'pond', 'trade', 'hearing', 'falling', 'femininity', 'old_jewish_man:', 'hoped', 'betcha', 'aisle', 'failure', 'beginning', 'remains', 'tries', 'sips', 'supreme', 'getup', 'one-hour', 'contemporary', 'soon', 'tonight', 'repairman', 'carl', 'reliable', 'conspiracy', 'heaving', 'starve', 'magnanimous', 'waters', 'blooded', 'lodge', 'commit', 'sleeps', 'incapable', 'suburban', 'emotion', 'tones', 'die-hard', 'comic', 'hems', 'word', \"scammin'\", \"rasputin's\", 'opens', 'draw', 'hoax', 'true', 'other_book_club_member:', 'marvelous', \"valentine's\", 'barbara', 'freaking', 'part', 'texas', 'glummy', 'something:', 'due', 'misfire', 'aidens', 'ask', 'uncle', 'highway', 'bret', 'expression', 'inches', 'itself', 'newsweek', 'spectacular', 'gift', 'tears', 'investigating', \"fendin'\", 'live', 'simon', 'supposed', 'entering', 'stick', 'uncomfortable', 'dreams', 'skin', 'earrings', 'roomy', 'plastic', 'administration', '8', 'brought', 'scientists', 'afford', 'infor', 'heave-ho', 'dimly', 'vulnerable', 'costume', 'privacy', 'ding-a-ding-ding-a-ding-ding', 'kind', 'drinking', 'backgammon', \"o'problem\", 'jazz', 'separator', 'skinny', 'wantcha', 'small_boy:', 'gordon', 'troy_mcclure:', 'sinister', 'smelling', 'replaced', \"tootin'\", 'ironed', 'weary', 'twin', 'las', 'paper', 'compels', 'honest', 'dyspeptic', 'it', 'myself', 'doll', 'bachelorhood', 'gargoyles', '1-800-555-hugs', 'deserve', 'hostages', 'edna_krabappel-flanders:', 'kisses', 'professor_jonathan_frink:', 'cock', 'exchange', 'sniffing', 'ticks', 'tribute', 'symphonies', 'unable', 'achem', \"'ceptin'\", 'physical', 'steinbrenner', 'dynamite', 'welcome', 'asking', \"wonderin'\", 'test', 'padre', 'represent', 'committing', 'see', 'night', 'invented', 'bam', 'whatever', 'comfortable', 'barely', 'betty:', 'multiple', 'secrets', 'kermit', 'macbeth', 'numeral', 'cigarettes', 'thinks', 'gum', 'ruin', 'idealistic', 'forced', 'explanation', 'oooh', 'beings', 'paris', 'remain', 'savings', 'plotz', 'awwww', 'dignified', 'sticking', 'sports_announcer:', 'exception:', 'karaoke', 'next', 'juice', \"son's\", 'gr-aargh', 'surprise', 'bad', 'annie', 'flowers', 'lot', 'genuinely', 'pantsless', 'paste', 'ale', 'derisive', 'duh', 'dads', 'walther_hotenhoffer:', 'liver', 'round', 'hide', \"show's\", 'wally:', 'delivery_man:', 'fact', 'killarney', 'arabs', 'front', 'dingy', 'sings', 'favorite', 'asks', 'jobless', 'slipped', 'swell', 'sugar-free', 'cooler', 'latin', 'script', 'lighting', 'eleven', 'suave', 'shhh', 'yells', 'swill', 'au', 'busiest', 'christian', 'prizefighters', \"doesn't\", 'grammys', 'blew', 'grampa_simpson:', 'corporate', 'hardwood', 'bell', 'past', 'crystal', 'stamp', 'fridge', 'bottom', 'measurements', 'british', 'heatherton', 'fink', 'kicks', 'thirsty', 'thrilled', 'sitar', 'amiable', 'tigers', \"'bout\", 'insist', 'philosophical', 'vampire', 'most', 'peach', 'ton', 'visas', 'democracy', 'smoker', 'fraud', 'scream', 'outs', 'dan', 'wikipedia', \"weren't\", 'f', 'whatsit', 'field', 'rubs', 'sir', 'life:', 'knives', 'app', \"choosin'\", 'meatpies', 'fringe', 'hafta', 'uncreeped-out', 'super-tough', 'gifts', 'louse', 'halloween', 'mcclure', 'ho', 'nine', 'sidekick', 'pity', 'puts', 'sacajawea', 'ow', 'terrific', 'celebrity', 'multi-purpose', 'doctor', 'simp-sonnnn', 'searching', 'doom', 'sheriff', 'strawberry', 'sitting', 'mess', 'fortress', 'mice', 'england', 'bought', 'bar_rag:', 'drawer', 'cracked', 'fans', 'stacey', 'surprised', 'hammock', 'wobble', 'woe:', 'handwriting', 'strain', 'you-need-man', 'huddle', 'riveting', 'weep', 'enemy', 'drinker', 'oh', 'sympathy', 'life-partner', 'burg', 'caricature', 'tongue', 'page', 'amused', 'patterns', 'worth', \"we'd\", 'girl-bart', \"you're\", 'longest', 'provide', 'cameras', 'boxing_announcer:', 'stink', 'gave', 'tease', 'stripe', 'unlucky', \"lisa's\", \"thing's\", 'take-back', '||question_mark||', 'raking', 'relaxing', 'warren', 'soaking', 'paramedic:', 'stealings', 'last', 'bender:', 'somebody', 'bathroom', 'drop-off', 'called', 'oughta', 'choose', 'vampires', 'gabriel', 'cowardly', 'send', 'father', 'competing', 'gotcha', 'embarrassed', 'faded', 'tokens', 'monkey', \"cashin'\", 'up-bup-bup', 'yoink', 'tommy', 'benefits', 'were', 'attitude', 'eight-year-old', 'grain', 'recorded', 'appalled', 'arrested:', 'met', 'arm', 'military', 'muttering', 'oblivious', \"sippin'\", \"number's\", 'pre-game', 'touches', 'cure', 'reflected', 'stirrers', 'baloney', \"sayin'\", 'so-ng', 'pancakes', 'legoland', 'inherent', 'powers', 'sheepish', 'napkins', 'patty_bouvier:', 'waltz', 'pronto', 'onion', 'wordloaf', 'nfl_narrator:', 'hurry', 'patron_#2:', 'mole', 'swig', 'want', 'broad', 'duffman', 'haircuts', 'enhance', 'nobody', 'debonair', 'mull', \"aren't\", 'wage', 'information', 'doll-baby', 'jewish', 'sanctuary', 'stays', 'sits', 'regulations', 'cars', \"where's\", 'soft', 'strongly', 'designer', 'large', 'railroad', 'sesame', 'overturned', 'size', 'beer-jerks', 'lorre', 'smooth', 'grope', 'about', 'hexa-', 'grimly', 'fan', 'started', \"spyin'\", 'non-american', 'excuses', 'karaoke_machine:', 'intrigued', 'comes', 'ripper', 'himself', 'checks', 'fluoroscope', 'humiliation', '250', 'some', 'gold', 'enthused', 'vegas', 'ten', \"'round\", 'twenty', 'gimme', 'thought', 'startup', 'feld', 'continued', 'charged', 'cent', 'whaddya', 'ref', 'possessions', 'seemed', 'yourselves', 'homer_', 'pantry', 'wow', 'darkness', 'self-satisfied', 'cell-ee', 'sidelines', 'puzzle', 'course', 'gee', 'royal', \"pickin'\", 'frenchman', 'travel', 'unhappy', 'motel', 'key', 'lowers', 'beach', 'insightful', 'pipes', 'mob', 'bathing', 'fritz', 'everyday', 'watashi', 'makes', 'agreement', 'specified', 'confused', 'plus', 'which', 'sale', 'mcbain', \"wasn't\", 'whispers', 'carlotta:', 'inspired', 'harvard', 'liability', 'term', 'celebration', 'cosmetics', 'sideshow_mel:', 'cutting', 'gunter', \"talkin'\", 'willy', 'patented', 'cheryl', \"'til\", 'brag', 'but', 'prove', 'suspiciously', 'marmaduke', 'totally', 'scoffs', 'logos', 'short_man:', 'laney_fontaine:', 'mayor', 'hurts', 'affects', 'slow', 'starla:', 'd', 'decide', 'craphole', 'load', 'accounta', \"fine-lookin'\", 'healthier', 'stunned', \"blowin'\", \"i'm\", 'food', 'richard', 'straining', 'spine', 'charter', 'avalanche', 'hero', 'sail', 'training', 'hollye', \"c'mom\", 'hours', 'clubs', 'producers', \"football's\", 'bulletin', \"'your\", 'fistiana', \"yesterday's\", 'yee-ha', 'squad', 'reminds', 'caholic', 'aged', 'buried', 'stopped', 'whirlybird', 'mountain', 'terrorizing', 'thinking', 'zack', 'presently', 'spelling', 'herself', 'desperate', 'could', 'r', 'low-life', 'newsletter', 'smiled', 'intimacy', 'rutabaga', 'killjoy', 'indignant', 'sincerely', 'potato', 'heh-heh', 'cloudy', 'taught', 'european', 'inspector', 'sound', 'his', 'device', 'jerky', 'mean', 'world-class', 'whoo', 'above', 'shag', 'streetcorner', \"'roids\", 'mister', 'directions', 'jasper_beardly:', 'drinks', 'earpiece', 'bush', 'lights', \"ya'\", 'nobel', 'scarf', 'inquiries', \"president's\", 'nods', '21', 'without', 'mmmm', 'boxing', 'log', 'marquee', 'ring', 're:', \"city's\", 'smiles', 'cap', 'dazed', 'grammy', 'newspaper', \"they're\", 'twenty-five', \"nixon's\", 'teddy', 'notice', 'teenage', 'employment', 'him', 'selective', 'dreamed', \"santa's\", 'protestantism', 'selection', 'kings', 'goodwill', 'vodka', 'nineteen', 'nachos', 'series', 'turlet', 'produce', 'fl', 'cruise', \"leavin'\", 'limits', 'fifteen', \"bein'\", 'early', 'pretend', 'prank', 'touchdown', 'tall', 'familiar', 'jockey', 'coast', 'queer', 'placed', 'christmas', 'chastity', 'notorious', \"knockin'\", 'soaked', 'reactions', 'heather', 'cletus_spuckler:', 'rookie', 'blokes', 'shoulder', 'los', 'promised', 'poison', 'albeit', \"grandmother's\", 'peace', 'quimby', 'why', 'least', 'corn', 'hmmmm', 'minute', 'followed', 'white_rabbit:', 'prepared', 'adrift', 'appendectomy', 'star', 'happen', 'rented', 'traditions', 'banks', 'sistine', 'sweden', 'future', 'problems', 'uninhibited', \"callin'\", 'us', 'warmth', 'seymour', 'woman_bystander:', 'loudly', 'headhunters', 'odd', 'rancid', 'hold', 'settlement', 'then:', 'items', \"it'd\", 'movie', 'none', 'exhaust', \"didn't\", 'channel', 'aerospace', 'meanwhile', 'distract', 'meaning', 'icy', 'my-y-y-y-y-y', 'fortune', 'resolution', 'scully', 'bathed', 'browns', 'mail', 'item', 'mom', 'website', 'decision', 'thorn', 'gear-head', 'jets', 'alright', 'pugilist', 'repay', 'space', 'hired', 'mmmmm', 'diets', 'contemplates', 'weekend', 'wind', 'adventure', 'fourteen:', 'knowledge', 'freak', 'poplar', 'selma_bouvier:', 'thanking', 'eyed', 'proposition', 'gentle', 'salvation', 'bragging', 'hundred', 'private', 'certificate', 'düffenbraus', 'thrown', 'woo-hoo', 'wigs', 'skirt', 'santa', \"daughter's\", 'killed', 'nitwit', 'portentous', 'birthday', 'anti-intellectualism', 'kinda', 'dutch', 'switch', 'chain', 'belch', 'elite', 'water', 'life-extension', 'in-ground', 'manuel', 'along', 'original', '/', \"mo'\", 'dignity', 'sells', 'detecting', 'sunglasses', 'leg', 'show-off', \"can't\", 'prefer', 'kids', 'immiggants', 'disgrace', 'after', 'rocks', 'mural', 'moonnnnnnnn', 'does', 'whaaaa', 'step', 'wistful', 'notices', 'pretentious_rat_lover:', 'drag', \"foolin'\", 'beanbag', 'malabar', \"'now\", 'navy', 'golf', 'rump', 'tenor:', 'philip', 'ferry', 'hearse', 'leans', 'great', 'gals', 'tee', 'slurred', 'dint', 'limited', 'whose', 'st', \"car's\", 'shaved', 'lifetime', 'tin', 'marjorie', 'data', 'emotional', 'twenty-two', 'writer:', 'weapon', 'bowl', 'sprawl', 'arms', 'carolina', \"o'reilly\", 'jer', 'necessary', 'hah', 'donut-shaped', 'site', 'x-men', 'closing', 'koholic', 'sneaky', \"team's\", 'soaps', 'investment', '4x4', 'pack', 'supermarket', 'calculate', 'walked', 'precious', 'granted', 'wacky', 'ohhhh', 'maher', \"'topes\", 'bits', 'north', 'wallet', 'wife-swapping', 'holiday', 'god', 'dirt', 'germans', 'creates', 'slop', \"tatum'll\", 'sharing', 'ballot', 'difficult', 'defeated', 'shrugs', 'municipal', 'contest', 'reptile', \"fightin'\", 'oopsie', 'boys', 'twice', 'neck', 'pint', 'supervising', 'willing', 'home', 'day', 'blown', 'carve', 'tap', 'switched', 'bulked', 'dishrag', 'nervous', 'ugliest', 'resenting', 'voice', 'sen', 'swigmore', 'rosey', 'wear', 'line', 'hunky', 'washer', 'gel', 'message', 'cobra', 'anyhoo', 'of', 'telling', 'always', 'whoopi', 'burglary', 'squeals', 'listening', 'pitcher', 'treat', 'civil', 'sport', 'winks', 'starts', 'pressure', 'bread', 'inspiring', 'slit', 'jacques', 'modern', 'noises', 'liar', 'strokkur', 'foodie', 'treasure', 'indeedy', 'island', 'adult_bart:', 'beatings', 'drank', 'helpful', 'lush', 'knew', 'feisty', 'brunch', 'bubbles', 'smelly', 'ho-ly', 'full-bodied', \"playin'\", 'throats', 'homunculus', 'facebook', 'ourselves'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.1\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following the tuple `(Input, Targets, LearingRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name=\"input\")\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name=\"Targets\")\n",
    "    lr = tf.placeholder(tf.float32, name=\"LearningRate\")\n",
    "    \n",
    "    return inputs, targets, lr\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    multi_rnn_cell = tf.contrib.rnn.MultiRNNCell([rnn_cell] * 3)\n",
    "    initial_state = tf.identity(multi_rnn_cell.zero_state(batch_size, tf.float32), name=\"initial_state\")\n",
    "    \n",
    "    return multi_rnn_cell, initial_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs, dtype=tf.float32)\n",
    "    return outputs, tf.identity(final_state, \"final_state\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    embed = get_embed(input_data=input_data, vocab_size=vocab_size, embed_dim=256)\n",
    "    outputs, final_state = build_rnn(cell, embed)\n",
    "    outputs = tf.concat(outputs, axis=1)\n",
    "    outputs = tf.reshape(outputs, [-1, rnn_size])\n",
    "    \n",
    "    w = tf.Variable(tf.truncated_normal((rnn_size, vocab_size), stddev=0.01))\n",
    "    b = tf.Variable(tf.ones(vocab_size))\n",
    "    logits = tf.matmul(outputs, w) + b\n",
    "    logits_shape = input_data.get_shape().as_list() + [vocab_size]\n",
    "    logits_shape[0] = -1\n",
    "    logits = tf.reshape(logits, logits_shape)\n",
    "    \n",
    "    return logits, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Batch of targets\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Batch of targets\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 128 5\n",
      "(1, 2, 128, 5)\n",
      "(2, 2, 128, 5)\n",
      "(3, 2, 128, 5)\n",
      "(4, 2, 128, 5)\n",
      "(5, 2, 128, 5)\n",
      "(6, 2, 128, 5)\n",
      "(7, 2, 128, 5)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_list = []\n",
    "    input_len = len(int_text)\n",
    "    print(input_len, batch_size, seq_length)\n",
    "    \n",
    "    total_iter = int(input_len / (batch_size * seq_length))\n",
    "    \n",
    "    for i in range(total_iter):\n",
    "        input_batch = []\n",
    "        target_batch = []\n",
    "        for j in range(batch_size):\n",
    "            input_seq = []\n",
    "            target_seq = []\n",
    "            for k in range(seq_length):\n",
    "                input_seq.append(int_text[batch_size * seq_length * i + seq_length * j + k])\n",
    "                target_seq.append(int_text[batch_size * seq_length * i + seq_length * j + k + 1])\n",
    "            input_batch.append(input_seq)\n",
    "            target_batch.append(target_seq)\n",
    "        \n",
    "        batch_list.append([input_batch, target_batch])\n",
    "        print(np.shape(batch_list))\n",
    "    \n",
    "    return np.array(batch_list)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 100\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "# RNN Size\n",
    "rnn_size = 128\n",
    "# Sequence Length\n",
    "seq_length = 128\n",
    "# Learning Rate\n",
    "learning_rate = 0.01\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 1000\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got -1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-33f70c17d6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minput_data_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_init_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Probabilities for generating words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-f4e245f538e5>\u001b[0m in \u001b[0;36mbuild_nn\u001b[0;34m(cell, rnn_size, input_data, vocab_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlogits_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlogits_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   2628\u001b[0m   \"\"\"\n\u001b[1;32m   2629\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[0;32m-> 2630\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   2631\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    492\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               raise TypeError(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    492\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                          as_ref=False):\n\u001b[1;32m    109\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m---> 99\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    100\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnumpy_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mproto_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FlattenToStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnumpy_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mproto_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FlattenToStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got -1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forms](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69116 256 128\n",
      "(1, 2, 256, 128)\n",
      "(2, 2, 256, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (256, 128) for Tensor 'input:0', which has shape '(?, 100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-396c263e7e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (256, 128) for Tensor 'input:0', which has shape '(?, 100)'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Parameters\n",
    "Save `seq_length` and `save_dir` for generating a new TV script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Generate Functions\n",
    "### Get Tensors\n",
    "Get tensors from `loaded_graph` using the function [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name).  Get the tensors using the following names:\n",
    "- \"input:0\"\n",
    "- \"initial_state:0\"\n",
    "- \"final_state:0\"\n",
    "- \"probs:0\"\n",
    "\n",
    "Return the tensors in the following tuple `(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return None, None, None, None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choose Word\n",
    "Implement the `pick_word()` function to select the next word using `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The TV Script is Nonsensical\n",
    "It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of [another dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data).  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
